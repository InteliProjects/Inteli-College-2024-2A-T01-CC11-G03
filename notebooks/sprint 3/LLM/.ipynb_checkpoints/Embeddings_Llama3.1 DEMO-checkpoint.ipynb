{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ollama in ./venv/lib/python3.12/site-packages (0.3.3)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in ./venv/lib/python3.12/site-packages (from ollama) (0.27.2)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.6.0)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.5)\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.10)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting llama-index==0.10.32\n",
      "  Downloading llama_index-0.10.32-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting llama-index-agent-openai<0.3.0,>=0.1.4 (from llama-index==0.10.32)\n",
      "  Downloading llama_index_agent_openai-0.2.9-py3-none-any.whl.metadata (729 bytes)\n",
      "Collecting llama-index-cli<0.2.0,>=0.1.2 (from llama-index==0.10.32)\n",
      "  Downloading llama_index_cli-0.1.13-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting llama-index-core<0.11.0,>=0.10.32 (from llama-index==0.10.32)\n",
      "  Downloading llama_index_core-0.10.68.post1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting llama-index-embeddings-openai<0.2.0,>=0.1.5 (from llama-index==0.10.32)\n",
      "  Downloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl.metadata (655 bytes)\n",
      "Collecting llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2 (from llama-index==0.10.32)\n",
      "  Downloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting llama-index-legacy<0.10.0,>=0.9.48 (from llama-index==0.10.32)\n",
      "  Downloading llama_index_legacy-0.9.48.post3-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting llama-index-llms-openai<0.2.0,>=0.1.13 (from llama-index==0.10.32)\n",
      "  Downloading llama_index_llms_openai-0.1.31-py3-none-any.whl.metadata (650 bytes)\n",
      "Collecting llama-index-multi-modal-llms-openai<0.2.0,>=0.1.3 (from llama-index==0.10.32)\n",
      "  Downloading llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl.metadata (728 bytes)\n",
      "Collecting llama-index-program-openai<0.2.0,>=0.1.3 (from llama-index==0.10.32)\n",
      "  Downloading llama_index_program_openai-0.1.7-py3-none-any.whl.metadata (760 bytes)\n",
      "Collecting llama-index-question-gen-openai<0.2.0,>=0.1.2 (from llama-index==0.10.32)\n",
      "  Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl.metadata (785 bytes)\n",
      "Collecting llama-index-readers-file<0.2.0,>=0.1.4 (from llama-index==0.10.32)\n",
      "  Downloading llama_index_readers_file-0.1.33-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting llama-index-readers-llama-parse<0.2.0,>=0.1.2 (from llama-index==0.10.32)\n",
      "  Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting openai>=1.14.0 (from llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.32)\n",
      "  Downloading openai-1.47.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./venv/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in ./venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (0.6.7)\n",
      "Collecting deprecated>=1.2.9.3 (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting dirtyjson<2.0.0,>=1.0.8 (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32)\n",
      "  Downloading dirtyjson-1.0.8-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting fsspec>=2023.5.0 (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32)\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: httpx in ./venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (1.6.0)\n",
      "Collecting networkx>=3.0 (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32)\n",
      "  Downloading networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting nltk!=3.9,>=3.8.1 (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: numpy<2.0.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (1.26.4)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (2.2.3)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (8.5.0)\n",
      "Collecting tiktoken>=0.3.3 (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32)\n",
      "  Downloading tiktoken-0.7.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting tqdm<5.0.0,>=4.66.1 (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (0.9.0)\n",
      "Collecting wrapt (from llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32)\n",
      "  Using cached wrapt-1.16.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Collecting llamaindex-py-client<0.2.0,>=0.1.19 (from llama-index-indices-managed-llama-cloud<0.2.0,>=0.1.2->llama-index==0.10.32)\n",
      "  Downloading llamaindex_py_client-0.1.19-py3-none-any.whl.metadata (760 bytes)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in ./venv/lib/python3.12/site-packages (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.32) (4.12.3)\n",
      "Collecting pypdf<5.0.0,>=4.0.1 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.32)\n",
      "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting striprtf<0.0.27,>=0.0.26 (from llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.32)\n",
      "  Downloading striprtf-0.0.26-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting llama-parse>=0.4.0 (from llama-index-readers-llama-parse<0.2.0,>=0.1.2->llama-index==0.10.32)\n",
      "  Downloading llama_parse-0.5.6-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (1.12.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./venv/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file<0.2.0,>=0.1.4->llama-index==0.10.32) (2.6)\n",
      "INFO: pip is looking at multiple versions of llama-parse to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading llama_parse-0.5.5-py3-none-any.whl.metadata (6.1 kB)\n",
      "  Downloading llama_parse-0.5.4-py3-none-any.whl.metadata (6.1 kB)\n",
      "  Downloading llama_parse-0.5.3-py3-none-any.whl.metadata (4.5 kB)\n",
      "  Downloading llama_parse-0.5.2-py3-none-any.whl.metadata (4.5 kB)\n",
      "  Downloading llama_parse-0.5.1-py3-none-any.whl.metadata (4.5 kB)\n",
      "  Downloading llama_parse-0.5.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "  Downloading llama_parse-0.4.9-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (4.6.0)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (1.0.5)\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (3.10)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (0.14.0)\n",
      "Collecting click (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting joblib (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting regex>=2021.8.3 (from nltk!=3.9,>=3.8.1->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32)\n",
      "  Downloading regex-2024.9.11-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting distro<2,>=1.7.0 (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.32)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai>=1.14.0->llama-index-agent-openai<0.3.0,>=0.1.4->llama-index==0.10.32)\n",
      "  Downloading jiter-0.5.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./venv/lib/python3.12/site-packages (from pydantic<3.0->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (2.2.3)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32)\n",
      "  Downloading greenlet-3.1.1-cp312-cp312-macosx_11_0_universal2.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (3.22.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.12/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (2024.2)\n",
      "Requirement already satisfied: packaging>=17.0 in ./venv/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (24.1)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.32->llama-index==0.10.32) (1.16.0)\n",
      "Downloading llama_index-0.10.32-py3-none-any.whl (6.9 kB)\n",
      "Downloading llama_index_agent_openai-0.2.9-py3-none-any.whl (13 kB)\n",
      "Downloading llama_index_cli-0.1.13-py3-none-any.whl (27 kB)\n",
      "Downloading llama_index_core-0.10.68.post1-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_embeddings_openai-0.1.11-py3-none-any.whl (6.3 kB)\n",
      "Downloading llama_index_indices_managed_llama_cloud-0.1.6-py3-none-any.whl (6.7 kB)\n",
      "Downloading llama_index_legacy-0.9.48.post3-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llama_index_llms_openai-0.1.31-py3-none-any.whl (12 kB)\n",
      "Downloading llama_index_multi_modal_llms_openai-0.1.9-py3-none-any.whl (5.9 kB)\n",
      "Downloading llama_index_program_openai-0.1.7-py3-none-any.whl (5.3 kB)\n",
      "Downloading llama_index_question_gen_openai-0.1.3-py3-none-any.whl (2.9 kB)\n",
      "Downloading llama_index_readers_file-0.1.33-py3-none-any.whl (38 kB)\n",
      "Downloading llama_index_readers_llama_parse-0.1.6-py3-none-any.whl (2.5 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llama_parse-0.4.9-py3-none-any.whl (9.4 kB)\n",
      "Downloading llamaindex_py_client-0.1.19-py3-none-any.whl (141 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hDownloading openai-1.47.1-py3-none-any.whl (375 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.6/375.6 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading striprtf-0.0.26-py3-none-any.whl (6.9 kB)\n",
      "Downloading tiktoken-0.7.0-cp312-cp312-macosx_11_0_arm64.whl (906 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.7/906.7 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached wrapt-1.16.0-cp312-cp312-macosx_11_0_arm64.whl (38 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading greenlet-3.1.1-cp312-cp312-macosx_11_0_universal2.whl (274 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.3/274.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiter-0.5.0-cp312-cp312-macosx_11_0_arm64.whl (296 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.0/297.0 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.9.11-cp312-cp312-macosx_11_0_arm64.whl (284 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.7/284.7 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: striprtf, dirtyjson, wrapt, tqdm, regex, pypdf, networkx, joblib, jiter, greenlet, fsspec, distro, click, tiktoken, nltk, deprecated, openai, llamaindex-py-client, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai, llama-index-legacy, llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai, llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index\n",
      "Successfully installed click-8.1.7 deprecated-1.2.14 dirtyjson-1.0.8 distro-1.9.0 fsspec-2024.9.0 greenlet-3.1.1 jiter-0.5.0 joblib-1.4.2 llama-index-0.10.32 llama-index-agent-openai-0.2.9 llama-index-cli-0.1.13 llama-index-core-0.10.68.post1 llama-index-embeddings-openai-0.1.11 llama-index-indices-managed-llama-cloud-0.1.6 llama-index-legacy-0.9.48.post3 llama-index-llms-openai-0.1.31 llama-index-multi-modal-llms-openai-0.1.9 llama-index-program-openai-0.1.7 llama-index-question-gen-openai-0.1.3 llama-index-readers-file-0.1.33 llama-index-readers-llama-parse-0.1.6 llama-parse-0.4.9 llamaindex-py-client-0.1.19 networkx-3.3 nltk-3.9.1 openai-1.47.1 pypdf-4.3.1 regex-2024.9.11 striprtf-0.0.26 tiktoken-0.7.0 tqdm-4.66.5 wrapt-1.16.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain in ./venv/lib/python3.12/site-packages (0.3.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.12/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.12/site-packages (from langchain) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./venv/lib/python3.12/site-packages (from langchain) (3.10.5)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in ./venv/lib/python3.12/site-packages (from langchain) (0.3.5)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in ./venv/lib/python3.12/site-packages (from langchain) (0.3.0)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./venv/lib/python3.12/site-packages (from langchain) (0.1.125)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in ./venv/lib/python3.12/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.12/site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.12/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./venv/lib/python3.12/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.12.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.6.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain) (3.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain_community in ./venv/lib/python3.12/site-packages (0.3.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./venv/lib/python3.12/site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./venv/lib/python3.12/site-packages (from langchain_community) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./venv/lib/python3.12/site-packages (from langchain_community) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./venv/lib/python3.12/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.0 in ./venv/lib/python3.12/site-packages (from langchain_community) (0.3.0)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in ./venv/lib/python3.12/site-packages (from langchain_community) (0.3.5)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in ./venv/lib/python3.12/site-packages (from langchain_community) (0.1.125)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in ./venv/lib/python3.12/site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in ./venv/lib/python3.12/site-packages (from langchain_community) (2.5.2)\n",
      "Requirement already satisfied: requests<3,>=2 in ./venv/lib/python3.12/site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./venv/lib/python3.12/site-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.12.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in ./venv/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.0->langchain_community) (0.3.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./venv/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.0->langchain_community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.112->langchain_community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.112->langchain_community) (3.10.7)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in ./venv/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain_community) (4.6.0)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain_community) (1.0.5)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.0->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.0->langchain_community) (2.23.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting llama-index-embeddings-ollama\n",
      "  Downloading llama_index_embeddings_ollama-0.3.1-py3-none-any.whl.metadata (693 bytes)\n",
      "Collecting llama-index-core<0.12.0,>=0.11.0 (from llama-index-embeddings-ollama)\n",
      "  Downloading llama_index_core-0.11.12-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: ollama<0.4.0,>=0.3.1 in ./venv/lib/python3.12/site-packages (from llama-index-embeddings-ollama) (0.3.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.1 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy>=1.4.49 in ./venv/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (3.10.5)\n",
      "Requirement already satisfied: dataclasses-json in ./venv/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (0.6.7)\n",
      "Requirement already satisfied: deprecated>=1.2.9.3 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (1.2.14)\n",
      "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (1.0.8)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (2024.9.0)\n",
      "Requirement already satisfied: httpx in ./venv/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (0.27.2)\n",
      "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (1.6.0)\n",
      "Requirement already satisfied: networkx>=3.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (3.3)\n",
      "Requirement already satisfied: nltk>3.8.1 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (3.9.1)\n",
      "Requirement already satisfied: numpy<2.0.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (1.26.4)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (10.4.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (2.9.2)\n",
      "Requirement already satisfied: requests>=2.31.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.2.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (8.5.0)\n",
      "Requirement already satisfied: tiktoken>=0.3.3 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (0.7.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (4.12.2)\n",
      "Requirement already satisfied: typing-inspect>=0.8.0 in ./venv/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (0.9.0)\n",
      "Requirement already satisfied: wrapt in ./venv/lib/python3.12/site-packages (from llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (1.12.1)\n",
      "Requirement already satisfied: anyio in ./venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (4.6.0)\n",
      "Requirement already satisfied: certifi in ./venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in ./venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (1.0.5)\n",
      "Requirement already satisfied: idna in ./venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (3.10)\n",
      "Requirement already satisfied: sniffio in ./venv/lib/python3.12/site-packages (from httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./venv/lib/python3.12/site-packages (from httpcore==1.*->httpx->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (0.14.0)\n",
      "Requirement already satisfied: click in ./venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in ./venv/lib/python3.12/site-packages (from nltk>3.8.1->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (2024.9.11)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in ./venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests>=2.31.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (2.2.3)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./venv/lib/python3.12/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (3.1.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./venv/lib/python3.12/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (1.0.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./venv/lib/python3.12/site-packages (from dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (3.22.0)\n",
      "Requirement already satisfied: packaging>=17.0 in ./venv/lib/python3.12/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.12.0,>=0.11.0->llama-index-embeddings-ollama) (24.1)\n",
      "Downloading llama_index_embeddings_ollama-0.3.1-py3-none-any.whl (2.6 kB)\n",
      "Downloading llama_index_core-0.11.12-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: llama-index-core, llama-index-embeddings-ollama\n",
      "  Attempting uninstall: llama-index-core\n",
      "    Found existing installation: llama-index-core 0.10.68.post1\n",
      "    Uninstalling llama-index-core-0.10.68.post1:\n",
      "      Successfully uninstalled llama-index-core-0.10.68.post1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llama-index-program-openai 0.1.7 requires llama-index-core<0.11.0,>=0.10.57, but you have llama-index-core 0.11.12 which is incompatible.\n",
      "llama-index-cli 0.1.13 requires llama-index-core<0.11.0,>=0.10.11.post1, but you have llama-index-core 0.11.12 which is incompatible.\n",
      "llama-index-llms-openai 0.1.31 requires llama-index-core<0.11.0,>=0.10.57, but you have llama-index-core 0.11.12 which is incompatible.\n",
      "llama-index-indices-managed-llama-cloud 0.1.6 requires llama-index-core<0.11.0,>=0.10.0, but you have llama-index-core 0.11.12 which is incompatible.\n",
      "llama-index-multi-modal-llms-openai 0.1.9 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.11.12 which is incompatible.\n",
      "llama-index-readers-llama-parse 0.1.6 requires llama-index-core<0.11.0,>=0.10.7, but you have llama-index-core 0.11.12 which is incompatible.\n",
      "llama-index-embeddings-openai 0.1.11 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.11.12 which is incompatible.\n",
      "llama-index-agent-openai 0.2.9 requires llama-index-core<0.11.0,>=0.10.41, but you have llama-index-core 0.11.12 which is incompatible.\n",
      "llama-index-readers-file 0.1.33 requires llama-index-core<0.11.0,>=0.10.37.post1, but you have llama-index-core 0.11.12 which is incompatible.\n",
      "llama-index-question-gen-openai 0.1.3 requires llama-index-core<0.11.0,>=0.10.1, but you have llama-index-core 0.11.12 which is incompatible.\n",
      "llama-index 0.10.32 requires llama-index-core<0.11.0,>=0.10.32, but you have llama-index-core 0.11.12 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed llama-index-core-0.11.12 llama-index-embeddings-ollama-0.3.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama\n",
    "!pip install llama-index==0.10.32\n",
    "!pip install langchain\n",
    "!pip install langchain_community\n",
    "!pip install llama-index-embeddings-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.17.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (4.1 kB)\n",
      "Collecting keras\n",
      "  Using cached keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp312-cp312-macosx_12_0_arm64.whl.metadata (13 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=3.10.0 (from tensorflow)\n",
      "  Using cached h5py-3.11.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.3.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-macosx_10_9_universal2.whl.metadata (20 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.12/site-packages (from tensorflow) (24.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-4.25.5-cp37-abi3-macosx_10_9_universal2.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in ./venv/lib/python3.12/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in ./venv/lib/python3.12/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.66.1-cp312-cp312-macosx_10_9_universal2.whl.metadata (3.9 kB)\n",
      "Collecting tensorboard<2.18,>=2.17 (from tensorflow)\n",
      "  Using cached tensorboard-2.17.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in ./venv/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Collecting rich (from keras)\n",
      "  Using cached rich-13.8.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras)\n",
      "  Using cached namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras)\n",
      "  Using cached optree-0.12.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (47 kB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./venv/lib/python3.12/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Using cached wheel-0.44.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./venv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.18,>=2.17->tensorflow)\n",
      "  Using cached Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.18,>=2.17->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.18,>=2.17->tensorflow)\n",
      "  Using cached werkzeug-3.0.4-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras)\n",
      "  Using cached markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./venv/lib/python3.12/site-packages (from rich->keras) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./venv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
      "Using cached tensorflow-2.17.0-cp312-cp312-macosx_12_0_arm64.whl (236.3 MB)\n",
      "Using cached keras-3.5.0-py3-none-any.whl (1.1 MB)\n",
      "Downloading scikit_learn-1.5.2-cp312-cp312-macosx_12_0_arm64.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[36m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Using cached gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Using cached grpcio-1.66.1-cp312-cp312-macosx_10_9_universal2.whl (10.6 MB)\n",
      "Using cached h5py-3.11.0-cp312-cp312-macosx_11_0_arm64.whl (2.9 MB)\n",
      "Using cached libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "Downloading ml_dtypes-0.4.1-cp312-cp312-macosx_10_9_universal2.whl (405 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.1/405.1 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Downloading protobuf-4.25.5-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.2/394.2 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
      "Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Using cached optree-0.12.1-cp312-cp312-macosx_11_0_arm64.whl (284 kB)\n",
      "Using cached rich-13.8.1-py3-none-any.whl (241 kB)\n",
      "Using cached Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Using cached werkzeug-3.0.4-py3-none-any.whl (227 kB)\n",
      "Using cached wheel-0.44.0-py3-none-any.whl (67 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wheel, werkzeug, threadpoolctl, termcolor, tensorboard-data-server, protobuf, optree, opt-einsum, ml-dtypes, mdurl, markdown, h5py, grpcio, google-pasta, gast, absl-py, tensorboard, scikit-learn, markdown-it-py, astunparse, rich, keras, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.66.1 h5py-3.11.0 keras-3.5.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 opt-einsum-3.3.0 optree-0.12.1 protobuf-4.25.5 rich-13.8.1 scikit-learn-1.5.2 tensorboard-2.17.1 tensorboard-data-server-0.7.2 tensorflow-2.17.0 termcolor-2.4.0 threadpoolctl-3.5.0 werkzeug-3.0.4 wheel-0.44.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow keras scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense, Concatenate, Input, LSTM, Dropout, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "from unittest.mock import patch, MagicMock\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import unittest\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/augmentend_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m chats_clients \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/augmentend_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m chats_clients\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/Documents/GitHub/2024-2A-T01-CC11-G03/notebooks/sprint 3/LLM/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/2024-2A-T01-CC11-G03/notebooks/sprint 3/LLM/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Documents/GitHub/2024-2A-T01-CC11-G03/notebooks/sprint 3/LLM/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/2024-2A-T01-CC11-G03/notebooks/sprint 3/LLM/venv/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Documents/GitHub/2024-2A-T01-CC11-G03/notebooks/sprint 3/LLM/venv/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/augmentend_data.csv'"
     ]
    }
   ],
   "source": [
    "chats_clients = pd.read_csv('data/augmented_data.csv')\n",
    "chats_clients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "model_id = \"llama3.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embedding(prompt):\n",
    "    return ollama.embeddings(model=model_id, prompt='Llamas are members of the camelid family')['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chats_clients['Pergunta_embedding'] = chats_clients['Pergunta'].apply(lambda prompt: get_sentence_embedding(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [-3.635859966278076, -0.8149826526641846, 1.08...\n",
       "1      [-3.635859966278076, -0.8149826526641846, 1.08...\n",
       "2      [-3.635859966278076, -0.8149826526641846, 1.08...\n",
       "3      [-3.635859966278076, -0.8149826526641846, 1.08...\n",
       "4      [-3.635859966278076, -0.8149826526641846, 1.08...\n",
       "                             ...                        \n",
       "169    [-3.635859966278076, -0.8149826526641846, 1.08...\n",
       "170    [-3.635859966278076, -0.8149826526641846, 1.08...\n",
       "171    [-3.635859966278076, -0.8149826526641846, 1.08...\n",
       "172    [-3.635859966278076, -0.8149826526641846, 1.08...\n",
       "173    [-3.635859966278076, -0.8149826526641846, 1.08...\n",
       "Name: Pergunta_embedding, Length: 174, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chats_clients['Pergunta_embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricsCallback(Callback):\n",
    "    def __init__(self, validation_data):\n",
    "        super().__init__()\n",
    "        self.validation_data = validation_data\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        val_data, val_labels = self.validation_data\n",
    "        val_pred = np.argmax(self.model.predict(val_data), axis=1)\n",
    "        val_f1 = f1_score(val_labels, val_pred, average='macro')\n",
    "        recall = recall_score(val_labels, val_pred, average='macro', zero_division=1)\n",
    "        print(f'Epoch {epoch + 1}: f1-score: {val_f1:.4f} - recall: {recall:.4f}')\n",
    "        logs['f1_score'] = val_f1\n",
    "        logs['recall'] = recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntentClassifier:\n",
    "    def __init__(self, epochs=300, batch_size=16, test_size=0.3, validation_split=0.3, learning_rate=0.001):\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.test_size = test_size\n",
    "        self.validation_split = validation_split\n",
    "        self.learning_rate = learning_rate\n",
    "        self.model = None\n",
    "        self.label_encoder = None\n",
    "\n",
    "    def prepare_data(self, chats_clients):\n",
    "        answer_embeddings = np.array(chats_clients['Pergunta_embedding'].tolist())\n",
    "\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.labels = self.label_encoder.fit_transform(chats_clients['Intencao'])\n",
    "\n",
    "        # Ajuste para garantir que a entrada seja 3D\n",
    "        answer_embeddings = answer_embeddings.reshape((answer_embeddings.shape[0], 1, answer_embeddings.shape[1]))\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(answer_embeddings, self.labels, test_size=self.test_size, random_state=42)\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def build_model(self, input_shape):\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=input_shape))\n",
    "        self.model.add(Dropout(0.4))\n",
    "        self.model.add(LSTM(64))\n",
    "        self.model.add(Dropout(0.4))\n",
    "        self.model.add(Dense(64, activation='relu'))\n",
    "        self.model.add(Dense(32, activation='relu'))\n",
    "        self.model.add(Dense(len(np.unique(self.labels)), activation='softmax'))\n",
    "        optimizer = Adam(learning_rate=self.learning_rate)\n",
    "        self.model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        self.model.summary()\n",
    "\n",
    "    def train(self, X_train, X_test, y_train, y_test):\n",
    "        model_checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "        # Callback do F1-Score e recall\n",
    "        metrics_callback = MetricsCallback(validation_data=(X_test, y_test))\n",
    "\n",
    "        H = self.model.fit(X_train, y_train, epochs=self.epochs,\n",
    "                       batch_size=self.batch_size,\n",
    "                       validation_split=self.validation_split,\n",
    "                       callbacks=[\n",
    "                           model_checkpoint,\n",
    "                           metrics_callback\n",
    "                           ])\n",
    "\n",
    "        loss, accuracy = self.model.evaluate(X_test, y_test)\n",
    "        print(f\"Test Loss: {loss}, Test Accuracy: {accuracy}\")\n",
    "\n",
    "        return H\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        return y_pred_classes\n",
    "\n",
    "    def generate_report(self, y_test, y_pred_classes):\n",
    "      print(len(y_test))\n",
    "      print(classification_report(y_test, y_pred_classes))\n",
    "\n",
    "    def evaluate_model(self, H):\n",
    "      # Obter métricas de precisão e perda do treinamento\n",
    "      acc = H.history['accuracy']\n",
    "      val_acc = H.history['val_accuracy']\n",
    "      loss = H.history['loss']\n",
    "      val_loss = H.history['val_loss']\n",
    "\n",
    "      epochs = range(1, len(acc) + 1)\n",
    "\n",
    "      # Plotar precisão do conjunto\n",
    "      plt.subplot(2, 2, 3)\n",
    "      plt.plot(epochs, acc, 'r', label='Precisão do Conjunto de Treino')\n",
    "      plt.plot(epochs, val_acc, 'b', label='Precisão do Conjunto de Validação')\n",
    "      plt.title('Precisão do Conjunto de Treino e Validação')\n",
    "      plt.xlabel('Épocas')\n",
    "      plt.ylabel('Precisão')\n",
    "      plt.legend()\n",
    "\n",
    "      # Plotar perda do conjunto\n",
    "      plt.subplot(2, 2, 4)\n",
    "      plt.plot(epochs, loss, 'r', label='Perda do Conjunto de Treino')\n",
    "      plt.plot(epochs, val_loss, 'b', label='Perda do Conjunto de Validação')\n",
    "      plt.title('Perda do Conjunto de Treino e Validação')\n",
    "      plt.xlabel('Épocas')\n",
    "      plt.ylabel('Perda')\n",
    "      plt.legend()\n",
    "\n",
    "      plt.tight_layout()\n",
    "      plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joaopedroalcaraz/Documents/GitHub/2024-2A-T01-CC11-G03/notebooks/sprint 3/LLM/venv/lib/python3.12/site-packages/keras/src/layers/rnn/bidirectional.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,326,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">82,176</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">495</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │     \u001b[38;5;34m4,326,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_5 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m82,176\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)             │           \u001b[38;5;34m495\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,415,311</span> (16.84 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,415,311\u001b[0m (16.84 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,415,311</span> (16.84 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,415,311\u001b[0m (16.84 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 138ms/step- accuracy: 0.0827 - loss: 2.\n",
      "Epoch 1: f1-score: 0.0145 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 118ms/step - accuracy: 0.0795 - loss: 2.7178 - val_accuracy: 0.0270 - val_loss: 2.7104 - f1_score: 0.0145 - recall: 0.0714\n",
      "Epoch 2/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepp - accuracy: 0.0892 - loss: 2.67\n",
      "Epoch 2: f1-score: 0.0145 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.0943 - loss: 2.6703 - val_accuracy: 0.0270 - val_loss: 2.6791 - f1_score: 0.0145 - recall: 0.0714\n",
      "Epoch 3/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepp - accuracy: 0.1849 - loss: 2.62\n",
      "Epoch 3: f1-score: 0.0145 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1713 - loss: 2.6229 - val_accuracy: 0.0270 - val_loss: 2.6460 - f1_score: 0.0145 - recall: 0.0714\n",
      "Epoch 4/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepp - accuracy: 0.1004 - loss: 2.54\n",
      "Epoch 4: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.1091 - loss: 2.5620 - val_accuracy: 0.1892 - val_loss: 2.6123 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 5/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2140 - loss: 2.526\n",
      "Epoch 5: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2141 - loss: 2.5288 - val_accuracy: 0.1892 - val_loss: 2.5964 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 6/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.3033 - loss: 2.471\n",
      "Epoch 6: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2779 - loss: 2.4767 - val_accuracy: 0.1892 - val_loss: 2.5924 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 7/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2258 - loss: 2.462\n",
      "Epoch 7: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2225 - loss: 2.4579 - val_accuracy: 0.1892 - val_loss: 2.5917 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 8/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2940 - loss: 2.459\n",
      "Epoch 8: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2746 - loss: 2.4572 - val_accuracy: 0.1892 - val_loss: 2.5944 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 9/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2269 - loss: 2.543\n",
      "Epoch 9: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2233 - loss: 2.5185 - val_accuracy: 0.1892 - val_loss: 2.5881 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 10/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.1835 - loss: 2.486\n",
      "Epoch 10: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1957 - loss: 2.4725 - val_accuracy: 0.1892 - val_loss: 2.5950 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 11/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.1731 - loss: 2.404\n",
      "Epoch 11: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1883 - loss: 2.4077 - val_accuracy: 0.1892 - val_loss: 2.5866 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 12/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepp - accuracy: 0.2748 - loss: 2.31\n",
      "Epoch 12: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2609 - loss: 2.3440 - val_accuracy: 0.1892 - val_loss: 2.5773 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 13/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2850 - loss: 2.348\n",
      "Epoch 13: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2682 - loss: 2.3605 - val_accuracy: 0.1892 - val_loss: 2.5788 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 14/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepp - accuracy: 0.2054 - loss: 2.37\n",
      "Epoch 14: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2114 - loss: 2.3868 - val_accuracy: 0.1892 - val_loss: 2.5859 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 15/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2356 - loss: 2.364\n",
      "Epoch 15: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2329 - loss: 2.3640 - val_accuracy: 0.1892 - val_loss: 2.5926 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 16/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2277 - loss: 2.402\n",
      "Epoch 16: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2273 - loss: 2.4062 - val_accuracy: 0.1892 - val_loss: 2.5965 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 17/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.3060 - loss: 2.219\n",
      "Epoch 17: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2716 - loss: 2.2920 - val_accuracy: 0.1892 - val_loss: 2.5915 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 18/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.3235 - loss: 2.272\n",
      "Epoch 18: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2957 - loss: 2.2995 - val_accuracy: 0.1892 - val_loss: 2.5914 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 19/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2304 - loss: 2.467\n",
      "Epoch 19: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2292 - loss: 2.4464 - val_accuracy: 0.1892 - val_loss: 2.5950 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 20/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.1631 - loss: 2.376\n",
      "Epoch 20: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1777 - loss: 2.3774 - val_accuracy: 0.1892 - val_loss: 2.6021 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 21/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2071 - loss: 2.317\n",
      "Epoch 21: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2091 - loss: 2.3391 - val_accuracy: 0.1892 - val_loss: 2.6166 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 22/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.3148 - loss: 2.248\n",
      "Epoch 22: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2895 - loss: 2.2949 - val_accuracy: 0.1892 - val_loss: 2.6134 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 23/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2006 - loss: 2.353\n",
      "Epoch 23: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2079 - loss: 2.3526 - val_accuracy: 0.1892 - val_loss: 2.6044 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 24/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2096 - loss: 2.412\n",
      "Epoch 24: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2143 - loss: 2.4028 - val_accuracy: 0.1892 - val_loss: 2.6021 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 25/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2096 - loss: 2.411\n",
      "Epoch 25: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2143 - loss: 2.3992 - val_accuracy: 0.1892 - val_loss: 2.5949 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 26/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2596 - loss: 2.394\n",
      "Epoch 26: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2500 - loss: 2.3916 - val_accuracy: 0.1892 - val_loss: 2.5905 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 27/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2408 - loss: 2.441\n",
      "Epoch 27: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2366 - loss: 2.4275 - val_accuracy: 0.1892 - val_loss: 2.5932 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 28/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2110 - loss: 2.421\n",
      "Epoch 28: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2154 - loss: 2.4135 - val_accuracy: 0.1892 - val_loss: 2.5942 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 29/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2517 - loss: 2.382\n",
      "Epoch 29: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2444 - loss: 2.3885 - val_accuracy: 0.1892 - val_loss: 2.6017 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 30/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2773 - loss: 2.288\n",
      "Epoch 30: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2553 - loss: 2.3296 - val_accuracy: 0.1892 - val_loss: 2.6094 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 31/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.1927 - loss: 2.463\n",
      "Epoch 31: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2069 - loss: 2.4308 - val_accuracy: 0.1892 - val_loss: 2.6104 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 32/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.1881 - loss: 2.439\n",
      "Epoch 32: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1990 - loss: 2.4247 - val_accuracy: 0.1892 - val_loss: 2.6183 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 33/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepp - accuracy: 0.2752 - loss: 2.32\n",
      "Epoch 33: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.2612 - loss: 2.3475 - val_accuracy: 0.1892 - val_loss: 2.6271 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 34/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2506 - loss: 2.353\n",
      "Epoch 34: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2436 - loss: 2.3550 - val_accuracy: 0.1892 - val_loss: 2.6248 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 35/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2433 - loss: 2.348\n",
      "Epoch 35: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2384 - loss: 2.3561 - val_accuracy: 0.1892 - val_loss: 2.6188 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 36/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2370 - loss: 2.329\n",
      "Epoch 36: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2322 - loss: 2.3399 - val_accuracy: 0.1892 - val_loss: 2.6364 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 37/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  - accuracy: 0.1452 - loss: 2.459\n",
      "Epoch 37: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1683 - loss: 2.4358 - val_accuracy: 0.1892 - val_loss: 2.6286 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 38/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2929 - loss: 2.366\n",
      "Epoch 38: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2739 - loss: 2.3710 - val_accuracy: 0.1892 - val_loss: 2.6272 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 39/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepp - accuracy: 0.1988 - loss: 2.40\n",
      "Epoch 39: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2032 - loss: 2.3922 - val_accuracy: 0.1892 - val_loss: 2.6138 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 40/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.1873 - loss: 2.371\n",
      "Epoch 40: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1984 - loss: 2.3694 - val_accuracy: 0.1892 - val_loss: 2.6028 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 41/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2102 - loss: 2.336\n",
      "Epoch 41: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2148 - loss: 2.3483 - val_accuracy: 0.1892 - val_loss: 2.5982 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 42/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/stepp - accuracy: 0.2648 - loss: 2.34\n",
      "Epoch 42: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2538 - loss: 2.3537 - val_accuracy: 0.1892 - val_loss: 2.5968 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 43/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2242 - loss: 2.338\n",
      "Epoch 43: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2247 - loss: 2.3485 - val_accuracy: 0.1892 - val_loss: 2.6095 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 44/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepp - accuracy: 0.2835 - loss: 2.33\n",
      "Epoch 44: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2672 - loss: 2.3514 - val_accuracy: 0.1892 - val_loss: 2.6133 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 45/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepp - accuracy: 0.1992 - loss: 2.40\n",
      "Epoch 45: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2069 - loss: 2.4001 - val_accuracy: 0.1892 - val_loss: 2.5988 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 46/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2642 - loss: 2.272\n",
      "Epoch 46: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2533 - loss: 2.3076 - val_accuracy: 0.1892 - val_loss: 2.5961 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 47/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2383 - loss: 2.411\n",
      "Epoch 47: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2349 - loss: 2.3978 - val_accuracy: 0.1892 - val_loss: 2.5926 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 48/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2377 - loss: 2.362\n",
      "Epoch 48: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2344 - loss: 2.3627 - val_accuracy: 0.1892 - val_loss: 2.5990 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 49/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepp - accuracy: 0.2373 - loss: 2.32\n",
      "Epoch 49: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2341 - loss: 2.3420 - val_accuracy: 0.1892 - val_loss: 2.6022 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 50/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2721 - loss: 2.358\n",
      "Epoch 50: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2590 - loss: 2.3656 - val_accuracy: 0.1892 - val_loss: 2.6104 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 51/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2085 - loss: 2.369\n",
      "Epoch 51: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2136 - loss: 2.3728 - val_accuracy: 0.1892 - val_loss: 2.6200 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 52/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2778 - loss: 2.364\n",
      "Epoch 52: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2471 - loss: 2.3744 - val_accuracy: 0.1892 - val_loss: 2.6128 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 53/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2357 - loss: 2.402\n",
      "Epoch 53: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2314 - loss: 2.3921 - val_accuracy: 0.1892 - val_loss: 2.6154 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 54/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.1988 - loss: 2.400\n",
      "Epoch 54: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2066 - loss: 2.3934 - val_accuracy: 0.1892 - val_loss: 2.6132 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 55/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/stepp - accuracy: 0.2985 - loss: 2.32\n",
      "Epoch 55: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2779 - loss: 2.3345 - val_accuracy: 0.1892 - val_loss: 2.6141 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 56/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepp - accuracy: 0.2044 - loss: 2.40\n",
      "Epoch 56: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2106 - loss: 2.3945 - val_accuracy: 0.1892 - val_loss: 2.6159 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 57/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepp - accuracy: 0.2044 - loss: 2.37\n",
      "Epoch 57: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2106 - loss: 2.3635 - val_accuracy: 0.1892 - val_loss: 2.6132 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 58/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2183 - loss: 2.366\n",
      "Epoch 58: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2206 - loss: 2.3640 - val_accuracy: 0.1892 - val_loss: 2.6078 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 59/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepp - accuracy: 0.2169 - loss: 2.37\n",
      "Epoch 59: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2195 - loss: 2.3762 - val_accuracy: 0.1892 - val_loss: 2.6166 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 60/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepp - accuracy: 0.2930 - loss: 2.34\n",
      "Epoch 60: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2642 - loss: 2.3545 - val_accuracy: 0.1892 - val_loss: 2.6194 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 61/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.1910 - loss: 2.391\n",
      "Epoch 61: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2161 - loss: 2.3757 - val_accuracy: 0.1892 - val_loss: 2.6179 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 62/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2318 - loss: 2.383\n",
      "Epoch 62: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2274 - loss: 2.3871 - val_accuracy: 0.1892 - val_loss: 2.6271 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 63/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepp - accuracy: 0.2721 - loss: 2.35\n",
      "Epoch 63: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2523 - loss: 2.3530 - val_accuracy: 0.1892 - val_loss: 2.6390 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 64/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.3283 - loss: 2.294\n",
      "Epoch 64: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2991 - loss: 2.3156 - val_accuracy: 0.1892 - val_loss: 2.6446 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 65/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2777 - loss: 2.254\n",
      "Epoch 65: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2630 - loss: 2.2802 - val_accuracy: 0.1892 - val_loss: 2.6426 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 66/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.1927 - loss: 2.462\n",
      "Epoch 66: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2087 - loss: 2.4336 - val_accuracy: 0.1892 - val_loss: 2.6336 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 67/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2057 - loss: 2.394\n",
      "Epoch 67: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2143 - loss: 2.3833 - val_accuracy: 0.1892 - val_loss: 2.6276 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 68/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2617 - loss: 2.339\n",
      "Epoch 68: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2515 - loss: 2.3488 - val_accuracy: 0.1892 - val_loss: 2.6271 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 69/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2433 - loss: 2.391\n",
      "Epoch 69: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2384 - loss: 2.3828 - val_accuracy: 0.1892 - val_loss: 2.6268 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 70/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepp - accuracy: 0.2206 - loss: 2.46\n",
      "Epoch 70: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2222 - loss: 2.4415 - val_accuracy: 0.1892 - val_loss: 2.6298 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 71/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepp - accuracy: 0.1571 - loss: 2.37\n",
      "Epoch 71: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1768 - loss: 2.3629 - val_accuracy: 0.1892 - val_loss: 2.6437 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 72/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2606 - loss: 2.347\n",
      "Epoch 72: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2508 - loss: 2.3445 - val_accuracy: 0.1892 - val_loss: 2.6567 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 73/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepp - accuracy: 0.2433 - loss: 2.27\n",
      "Epoch 73: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2384 - loss: 2.3121 - val_accuracy: 0.1892 - val_loss: 2.6575 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 74/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2669 - loss: 2.334\n",
      "Epoch 74: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2553 - loss: 2.3412 - val_accuracy: 0.1892 - val_loss: 2.6343 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 75/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2090 - loss: 2.358\n",
      "Epoch 75: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2139 - loss: 2.3592 - val_accuracy: 0.1892 - val_loss: 2.6229 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 76/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2090 - loss: 2.378\n",
      "Epoch 76: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2139 - loss: 2.3659 - val_accuracy: 0.1892 - val_loss: 2.6092 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 77/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2135 - loss: 2.354\n",
      "Epoch 77: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2188 - loss: 2.3552 - val_accuracy: 0.1892 - val_loss: 2.6120 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 78/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2279 - loss: 2.337\n",
      "Epoch 78: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2252 - loss: 2.3520 - val_accuracy: 0.1892 - val_loss: 2.6223 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 79/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/stepp - accuracy: 0.1901 - loss: 2.30\n",
      "Epoch 79: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2072 - loss: 2.3239 - val_accuracy: 0.1892 - val_loss: 2.6330 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 80/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.1836 - loss: 2.357\n",
      "Epoch 80: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2017 - loss: 2.3562 - val_accuracy: 0.1892 - val_loss: 2.6268 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 81/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepp - accuracy: 0.2005 - loss: 2.33\n",
      "Epoch 81: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2096 - loss: 2.3594 - val_accuracy: 0.1892 - val_loss: 2.6321 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 82/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2231 - loss: 2.375\n",
      "Epoch 82: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2240 - loss: 2.3660 - val_accuracy: 0.1892 - val_loss: 2.6313 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 83/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2346 - loss: 2.348\n",
      "Epoch 83: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2322 - loss: 2.3618 - val_accuracy: 0.1892 - val_loss: 2.6393 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 84/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2431 - loss: 2.371\n",
      "Epoch 84: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2344 - loss: 2.3549 - val_accuracy: 0.1892 - val_loss: 2.6415 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 85/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2161 - loss: 2.378\n",
      "Epoch 85: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2221 - loss: 2.3712 - val_accuracy: 0.1892 - val_loss: 2.6402 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 86/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.3034 - loss: 2.358\n",
      "Epoch 86: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2701 - loss: 2.3497 - val_accuracy: 0.1892 - val_loss: 2.6323 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 87/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2518 - loss: 2.309\n",
      "Epoch 87: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2481 - loss: 2.3154 - val_accuracy: 0.1892 - val_loss: 2.6305 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 88/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2292 - loss: 2.388\n",
      "Epoch 88: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2295 - loss: 2.3823 - val_accuracy: 0.1892 - val_loss: 2.6212 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 89/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2310 - loss: 2.323\n",
      "Epoch 89: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2297 - loss: 2.3274 - val_accuracy: 0.1892 - val_loss: 2.6136 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 90/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2492 - loss: 2.370\n",
      "Epoch 90: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2459 - loss: 2.3721 - val_accuracy: 0.1892 - val_loss: 2.5999 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 91/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepp - accuracy: 0.1992 - loss: 2.36\n",
      "Epoch 91: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2088 - loss: 2.3660 - val_accuracy: 0.1892 - val_loss: 2.5794 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 92/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.1971 - loss: 2.366\n",
      "Epoch 92: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2054 - loss: 2.3673 - val_accuracy: 0.1892 - val_loss: 2.5638 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 93/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2266 - loss: 2.384\n",
      "Epoch 93: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2280 - loss: 2.3708 - val_accuracy: 0.1892 - val_loss: 2.5572 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 94/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step  - accuracy: 0.2031 - loss: 2.372\n",
      "Epoch 94: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2128 - loss: 2.3706 - val_accuracy: 0.1892 - val_loss: 2.5628 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 95/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.1972 - loss: 2.417\n",
      "Epoch 95: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2014 - loss: 2.4088 - val_accuracy: 0.1892 - val_loss: 2.5743 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 96/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  - accuracy: 0.1849 - loss: 2.414\n",
      "Epoch 96: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1989 - loss: 2.3957 - val_accuracy: 0.1892 - val_loss: 2.5970 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 97/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2663 - loss: 2.324\n",
      "Epoch 97: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2548 - loss: 2.3413 - val_accuracy: 0.1892 - val_loss: 2.6149 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 98/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2708 - loss: 2.349\n",
      "Epoch 98: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2533 - loss: 2.3631 - val_accuracy: 0.1892 - val_loss: 2.6241 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 99/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2262 - loss: 2.344\n",
      "Epoch 99: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2262 - loss: 2.3477 - val_accuracy: 0.1892 - val_loss: 2.6280 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 100/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2071 - loss: 2.436\n",
      "Epoch 100: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2125 - loss: 2.4221 - val_accuracy: 0.1892 - val_loss: 2.6195 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 101/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2096 - loss: 2.355\n",
      "Epoch 101: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2183 - loss: 2.3548 - val_accuracy: 0.1892 - val_loss: 2.6254 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 102/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.1992 - loss: 2.456\n",
      "Epoch 102: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2106 - loss: 2.4257 - val_accuracy: 0.1892 - val_loss: 2.6305 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 103/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2279 - loss: 2.394\n",
      "Epoch 103: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2288 - loss: 2.3792 - val_accuracy: 0.1892 - val_loss: 2.6286 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 104/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2106 - loss: 2.350\n",
      "Epoch 104: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2151 - loss: 2.3515 - val_accuracy: 0.1892 - val_loss: 2.6259 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 105/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepp - accuracy: 0.2512 - loss: 2.31\n",
      "Epoch 105: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2441 - loss: 2.3273 - val_accuracy: 0.1892 - val_loss: 2.6233 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 106/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2656 - loss: 2.382\n",
      "Epoch 106: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2486 - loss: 2.3913 - val_accuracy: 0.1892 - val_loss: 2.6254 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 107/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.1981 - loss: 2.398\n",
      "Epoch 107: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2061 - loss: 2.3850 - val_accuracy: 0.1892 - val_loss: 2.6302 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 108/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.1940 - loss: 2.389\n",
      "Epoch 108: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2094 - loss: 2.3802 - val_accuracy: 0.1892 - val_loss: 2.6313 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 109/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepp - accuracy: 0.1523 - loss: 2.38\n",
      "Epoch 109: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.1820 - loss: 2.3798 - val_accuracy: 0.1892 - val_loss: 2.6315 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 110/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepp - accuracy: 0.2283 - loss: 2.34\n",
      "Epoch 110: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2277 - loss: 2.3469 - val_accuracy: 0.1892 - val_loss: 2.6362 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 111/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2127 - loss: 2.412\n",
      "Epoch 111: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2166 - loss: 2.3992 - val_accuracy: 0.1892 - val_loss: 2.6389 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 112/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2565 - loss: 2.425\n",
      "Epoch 112: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2433 - loss: 2.4094 - val_accuracy: 0.1892 - val_loss: 2.6431 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 113/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepp - accuracy: 0.2127 - loss: 2.37\n",
      "Epoch 113: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2166 - loss: 2.3668 - val_accuracy: 0.1892 - val_loss: 2.6441 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 114/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepp - accuracy: 0.2017 - loss: 2.40\n",
      "Epoch 114: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2087 - loss: 2.3972 - val_accuracy: 0.1892 - val_loss: 2.6384 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 115/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepp - accuracy: 0.2591 - loss: 2.32\n",
      "Epoch 115: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2448 - loss: 2.3383 - val_accuracy: 0.1892 - val_loss: 2.6405 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 116/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepp - accuracy: 0.1981 - loss: 2.41\n",
      "Epoch 116: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2061 - loss: 2.4077 - val_accuracy: 0.1892 - val_loss: 2.6400 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 117/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.1310 - loss: 2.442\n",
      "Epoch 117: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1582 - loss: 2.4185 - val_accuracy: 0.1892 - val_loss: 2.6454 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 118/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2643 - loss: 2.324\n",
      "Epoch 118: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2496 - loss: 2.3524 - val_accuracy: 0.1892 - val_loss: 2.6543 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 119/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepp - accuracy: 0.2606 - loss: 2.27\n",
      "Epoch 119: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2508 - loss: 2.2997 - val_accuracy: 0.1892 - val_loss: 2.6589 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 120/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2196 - loss: 2.358\n",
      "Epoch 120: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2206 - loss: 2.3546 - val_accuracy: 0.1892 - val_loss: 2.6510 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 121/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepp - accuracy: 0.1819 - loss: 2.41\n",
      "Epoch 121: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1945 - loss: 2.3994 - val_accuracy: 0.1892 - val_loss: 2.6465 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 122/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2283 - loss: 2.365\n",
      "Epoch 122: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2277 - loss: 2.3672 - val_accuracy: 0.1892 - val_loss: 2.6538 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 123/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepp - accuracy: 0.1875 - loss: 2.40\n",
      "Epoch 123: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2057 - loss: 2.3801 - val_accuracy: 0.1892 - val_loss: 2.6544 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 124/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  - accuracy: 0.2338 - loss: 2.322\n",
      "Epoch 124: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2282 - loss: 2.3334 - val_accuracy: 0.1892 - val_loss: 2.6532 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 125/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.1953 - loss: 2.334\n",
      "Epoch 125: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2066 - loss: 2.3374 - val_accuracy: 0.1892 - val_loss: 2.6514 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 126/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2396 - loss: 2.314\n",
      "Epoch 126: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2355 - loss: 2.3248 - val_accuracy: 0.1892 - val_loss: 2.6550 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 127/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  - accuracy: 0.2511 - loss: 2.344\n",
      "Epoch 127: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.2475 - loss: 2.3471 - val_accuracy: 0.1892 - val_loss: 2.6436 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 128/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2535 - loss: 2.382\n",
      "Epoch 128: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2322 - loss: 2.3670 - val_accuracy: 0.1892 - val_loss: 2.6411 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 129/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.1981 - loss: 2.412\n",
      "Epoch 129: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2061 - loss: 2.4013 - val_accuracy: 0.1892 - val_loss: 2.6401 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 130/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.1637 - loss: 2.390\n",
      "Epoch 130: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.1816 - loss: 2.3816 - val_accuracy: 0.1892 - val_loss: 2.6396 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 131/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.1860 - loss: 2.376\n",
      "Epoch 131: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1975 - loss: 2.3716 - val_accuracy: 0.1892 - val_loss: 2.6349 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 132/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2683 - loss: 2.295\n",
      "Epoch 132: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2563 - loss: 2.3151 - val_accuracy: 0.1892 - val_loss: 2.6247 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 133/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  - accuracy: 0.2448 - loss: 2.390\n",
      "Epoch 133: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2366 - loss: 2.3875 - val_accuracy: 0.1892 - val_loss: 2.6134 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 134/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  - accuracy: 0.2627 - loss: 2.306\n",
      "Epoch 134: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2575 - loss: 2.3158 - val_accuracy: 0.1892 - val_loss: 2.6104 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 135/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepp - accuracy: 0.2122 - loss: 2.25\n",
      "Epoch 135: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2163 - loss: 2.3020 - val_accuracy: 0.1892 - val_loss: 2.6128 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 136/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepp - accuracy: 0.2118 - loss: 2.39\n",
      "Epoch 136: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2139 - loss: 2.3903 - val_accuracy: 0.1892 - val_loss: 2.6180 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 137/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepp - accuracy: 0.2377 - loss: 2.41\n",
      "Epoch 137: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2344 - loss: 2.4042 - val_accuracy: 0.1892 - val_loss: 2.6234 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 138/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2329 - loss: 2.326\n",
      "Epoch 138: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2310 - loss: 2.3354 - val_accuracy: 0.1892 - val_loss: 2.6286 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 139/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2840 - loss: 2.332\n",
      "Epoch 139: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2675 - loss: 2.3406 - val_accuracy: 0.1892 - val_loss: 2.6222 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 140/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  - accuracy: 0.2273 - loss: 2.386\n",
      "Epoch 140: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2270 - loss: 2.3785 - val_accuracy: 0.1892 - val_loss: 2.6123 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 141/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2610 - loss: 2.277\n",
      "Epoch 141: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2511 - loss: 2.3084 - val_accuracy: 0.1892 - val_loss: 2.6177 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 142/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepp - accuracy: 0.1880 - loss: 2.42\n",
      "Epoch 142: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1935 - loss: 2.4127 - val_accuracy: 0.1892 - val_loss: 2.6182 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 143/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  - accuracy: 0.2214 - loss: 2.385\n",
      "Epoch 143: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2233 - loss: 2.3817 - val_accuracy: 0.1892 - val_loss: 2.6336 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 144/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2273 - loss: 2.278\n",
      "Epoch 144: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2270 - loss: 2.3026 - val_accuracy: 0.1892 - val_loss: 2.6601 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 145/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2117 - loss: 2.373\n",
      "Epoch 145: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2158 - loss: 2.3714 - val_accuracy: 0.1892 - val_loss: 2.6650 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 146/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2683 - loss: 2.304\n",
      "Epoch 146: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2563 - loss: 2.3264 - val_accuracy: 0.1892 - val_loss: 2.6675 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 147/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/stepp - accuracy: 0.1571 - loss: 2.45\n",
      "Epoch 147: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.1768 - loss: 2.4234 - val_accuracy: 0.1892 - val_loss: 2.6555 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 148/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2552 - loss: 2.257\n",
      "Epoch 148: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2444 - loss: 2.2938 - val_accuracy: 0.1892 - val_loss: 2.6523 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 149/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepp - accuracy: 0.2252 - loss: 2.40\n",
      "Epoch 149: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2255 - loss: 2.3881 - val_accuracy: 0.1892 - val_loss: 2.6379 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 150/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2565 - loss: 2.390\n",
      "Epoch 150: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2433 - loss: 2.3816 - val_accuracy: 0.1892 - val_loss: 2.6388 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 151/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2617 - loss: 2.374\n",
      "Epoch 151: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2445 - loss: 2.3748 - val_accuracy: 0.1892 - val_loss: 2.6418 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 152/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2188 - loss: 2.336\n",
      "Epoch 152: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2218 - loss: 2.3398 - val_accuracy: 0.1892 - val_loss: 2.6531 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 153/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2731 - loss: 2.320\n",
      "Epoch 153: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.2664 - loss: 2.3273 - val_accuracy: 0.1892 - val_loss: 2.6530 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 154/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  - accuracy: 0.2682 - loss: 2.274\n",
      "Epoch 154: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2500 - loss: 2.3079 - val_accuracy: 0.1892 - val_loss: 2.6437 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 155/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2068 - loss: 2.344\n",
      "Epoch 155: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2096 - loss: 2.3454 - val_accuracy: 0.1892 - val_loss: 2.6336 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 156/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2878 - loss: 2.280\n",
      "Epoch 156: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2630 - loss: 2.3202 - val_accuracy: 0.1892 - val_loss: 2.6290 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 157/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2448 - loss: 2.314\n",
      "Epoch 157: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2366 - loss: 2.3423 - val_accuracy: 0.1892 - val_loss: 2.6315 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 158/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2057 - loss: 2.310\n",
      "Epoch 158: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2108 - loss: 2.3330 - val_accuracy: 0.1892 - val_loss: 2.6414 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 159/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2552 - loss: 2.315\n",
      "Epoch 159: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2511 - loss: 2.3190 - val_accuracy: 0.1892 - val_loss: 2.6589 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 160/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2370 - loss: 2.354\n",
      "Epoch 160: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2322 - loss: 2.3615 - val_accuracy: 0.1892 - val_loss: 2.6501 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 161/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2812 - loss: 2.349\n",
      "Epoch 161: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2575 - loss: 2.3648 - val_accuracy: 0.1892 - val_loss: 2.6367 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 162/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2819 - loss: 2.281\n",
      "Epoch 162: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2660 - loss: 2.3075 - val_accuracy: 0.1892 - val_loss: 2.6264 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 163/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2431 - loss: 2.308\n",
      "Epoch 163: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2407 - loss: 2.3153 - val_accuracy: 0.1892 - val_loss: 2.6118 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 164/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  - accuracy: 0.2200 - loss: 2.368\n",
      "Epoch 164: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2218 - loss: 2.3642 - val_accuracy: 0.1892 - val_loss: 2.6104 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 165/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  - accuracy: 0.2065 - loss: 2.357\n",
      "Epoch 165: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2121 - loss: 2.3557 - val_accuracy: 0.1892 - val_loss: 2.6196 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 166/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2253 - loss: 2.354\n",
      "Epoch 166: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2273 - loss: 2.3541 - val_accuracy: 0.1892 - val_loss: 2.6318 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 167/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.1510 - loss: 2.438\n",
      "Epoch 167: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.1813 - loss: 2.4040 - val_accuracy: 0.1892 - val_loss: 2.6387 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 168/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.1979 - loss: 2.424\n",
      "Epoch 168: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2099 - loss: 2.3987 - val_accuracy: 0.1892 - val_loss: 2.6581 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 169/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2201 - loss: 2.390\n",
      "Epoch 169: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2225 - loss: 2.3760 - val_accuracy: 0.1892 - val_loss: 2.6631 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 170/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2279 - loss: 2.353\n",
      "Epoch 170: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2270 - loss: 2.3701 - val_accuracy: 0.1892 - val_loss: 2.6631 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 171/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.1523 - loss: 2.380\n",
      "Epoch 171: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.1820 - loss: 2.3722 - val_accuracy: 0.1892 - val_loss: 2.6595 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 172/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/stepp - accuracy: 0.2591 - loss: 2.29\n",
      "Epoch 172: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2466 - loss: 2.3225 - val_accuracy: 0.1892 - val_loss: 2.6562 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 173/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/stepp - accuracy: 0.2301 - loss: 2.38\n",
      "Epoch 173: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2295 - loss: 2.3839 - val_accuracy: 0.1892 - val_loss: 2.6456 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 174/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2214 - loss: 2.364\n",
      "Epoch 174: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2215 - loss: 2.3701 - val_accuracy: 0.1892 - val_loss: 2.6406 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 175/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.1898 - loss: 2.398\n",
      "Epoch 175: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.1950 - loss: 2.3944 - val_accuracy: 0.1892 - val_loss: 2.6398 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 176/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2370 - loss: 2.336\n",
      "Epoch 176: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2340 - loss: 2.3550 - val_accuracy: 0.1892 - val_loss: 2.6449 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 177/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.3190 - loss: 2.172\n",
      "Epoch 177: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2925 - loss: 2.2275 - val_accuracy: 0.1892 - val_loss: 2.6511 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 178/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  - accuracy: 0.1835 - loss: 2.329\n",
      "Epoch 178: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.1957 - loss: 2.3357 - val_accuracy: 0.1892 - val_loss: 2.6418 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 179/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2096 - loss: 2.418\n",
      "Epoch 179: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2166 - loss: 2.3921 - val_accuracy: 0.1892 - val_loss: 2.6401 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 180/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  - accuracy: 0.2161 - loss: 2.370\n",
      "Epoch 180: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2221 - loss: 2.3710 - val_accuracy: 0.1892 - val_loss: 2.6400 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 181/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  - accuracy: 0.2444 - loss: 2.318\n",
      "Epoch 181: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.2392 - loss: 2.3338 - val_accuracy: 0.1892 - val_loss: 2.6440 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 182/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2669 - loss: 2.315\n",
      "Epoch 182: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2475 - loss: 2.3366 - val_accuracy: 0.1892 - val_loss: 2.6439 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 183/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2474 - loss: 2.313\n",
      "Epoch 183: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2364 - loss: 2.3393 - val_accuracy: 0.1892 - val_loss: 2.6454 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 184/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2387 - loss: 2.362\n",
      "Epoch 184: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2352 - loss: 2.3633 - val_accuracy: 0.1892 - val_loss: 2.6476 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 185/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2163 - loss: 2.446\n",
      "Epoch 185: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2191 - loss: 2.4236 - val_accuracy: 0.1892 - val_loss: 2.6440 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 186/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  - accuracy: 0.2396 - loss: 2.350\n",
      "Epoch 186: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2337 - loss: 2.3524 - val_accuracy: 0.1892 - val_loss: 2.6469 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 187/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  - accuracy: 0.2210 - loss: 2.380\n",
      "Epoch 187: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2218 - loss: 2.3783 - val_accuracy: 0.1892 - val_loss: 2.6463 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 188/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  - accuracy: 0.1915 - loss: 2.404\n",
      "Epoch 188: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.1965 - loss: 2.3966 - val_accuracy: 0.1892 - val_loss: 2.6569 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 189/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.1808 - loss: 2.412\n",
      "Epoch 189: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1872 - loss: 2.4013 - val_accuracy: 0.1892 - val_loss: 2.6572 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 190/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2383 - loss: 2.336\n",
      "Epoch 190: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2347 - loss: 2.3492 - val_accuracy: 0.1892 - val_loss: 2.6565 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 191/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  - accuracy: 0.2188 - loss: 2.462\n",
      "Epoch 191: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2218 - loss: 2.4213 - val_accuracy: 0.1892 - val_loss: 2.6514 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 192/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2174 - loss: 2.335\n",
      "Epoch 192: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2228 - loss: 2.3419 - val_accuracy: 0.1892 - val_loss: 2.6543 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 193/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2371 - loss: 2.313\n",
      "Epoch 193: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.2340 - loss: 2.3225 - val_accuracy: 0.1892 - val_loss: 2.6414 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 194/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.3008 - loss: 2.207\n",
      "Epoch 194: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.2686 - loss: 2.2732 - val_accuracy: 0.1892 - val_loss: 2.6348 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 195/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.1888 - loss: 2.356\n",
      "Epoch 195: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2029 - loss: 2.3535 - val_accuracy: 0.1892 - val_loss: 2.6292 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 196/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  - accuracy: 0.1862 - loss: 2.425\n",
      "Epoch 196: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2014 - loss: 2.3965 - val_accuracy: 0.1892 - val_loss: 2.6296 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 197/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2735 - loss: 2.249\n",
      "Epoch 197: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2600 - loss: 2.2737 - val_accuracy: 0.1892 - val_loss: 2.6441 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 198/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.1719 - loss: 2.3738\n",
      "Epoch 198: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1950 - loss: 2.3597 - val_accuracy: 0.1892 - val_loss: 2.6553 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 199/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.1458 - loss: 2.344\n",
      "Epoch 199: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1783 - loss: 2.3540 - val_accuracy: 0.1892 - val_loss: 2.6642 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 200/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  - accuracy: 0.2526 - loss: 2.346\n",
      "Epoch 200: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2429 - loss: 2.3634 - val_accuracy: 0.1892 - val_loss: 2.6673 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 201/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2240 - loss: 2.382\n",
      "Epoch 201: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2247 - loss: 2.3766 - val_accuracy: 0.1892 - val_loss: 2.6650 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 202/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2256 - loss: 2.411\n",
      "Epoch 202: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2258 - loss: 2.3956 - val_accuracy: 0.1892 - val_loss: 2.6570 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 203/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2826 - loss: 2.263\n",
      "Epoch 203: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2600 - loss: 2.3060 - val_accuracy: 0.1892 - val_loss: 2.6566 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 204/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2815 - loss: 2.309\n",
      "Epoch 204: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2657 - loss: 2.3270 - val_accuracy: 0.1892 - val_loss: 2.6528 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 205/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2523 - loss: 2.267\n",
      "Epoch 205: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2448 - loss: 2.2943 - val_accuracy: 0.1892 - val_loss: 2.6522 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 206/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2066 - loss: 2.363\n",
      "Epoch 206: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2094 - loss: 2.3590 - val_accuracy: 0.1892 - val_loss: 2.6555 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 207/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2201 - loss: 2.314\n",
      "Epoch 207: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.2225 - loss: 2.3258 - val_accuracy: 0.1892 - val_loss: 2.6578 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 208/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  - accuracy: 0.2266 - loss: 2.364\n",
      "Epoch 208: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2262 - loss: 2.3665 - val_accuracy: 0.1892 - val_loss: 2.6587 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 209/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  - accuracy: 0.2734 - loss: 2.278\n",
      "Epoch 209: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2512 - loss: 2.3115 - val_accuracy: 0.1892 - val_loss: 2.6611 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 210/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  - accuracy: 0.2174 - loss: 2.294\n",
      "Epoch 210: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2192 - loss: 2.3211 - val_accuracy: 0.1892 - val_loss: 2.6709 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 211/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  - accuracy: 0.3021 - loss: 2.255\n",
      "Epoch 211: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.2913 - loss: 2.2719 - val_accuracy: 0.1892 - val_loss: 2.6754 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 212/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2600 - loss: 2.325\n",
      "Epoch 212: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2503 - loss: 2.3342 - val_accuracy: 0.1892 - val_loss: 2.6660 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 213/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.1527 - loss: 2.505\n",
      "Epoch 213: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1737 - loss: 2.4688 - val_accuracy: 0.1892 - val_loss: 2.6519 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 214/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2013 - loss: 2.325\n",
      "Epoch 214: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.2084 - loss: 2.3363 - val_accuracy: 0.1892 - val_loss: 2.6445 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 215/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.3333 - loss: 2.273\n",
      "Epoch 215: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2838 - loss: 2.3122 - val_accuracy: 0.1892 - val_loss: 2.6399 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 216/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2631 - loss: 2.300\n",
      "Epoch 216: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2526 - loss: 2.3120 - val_accuracy: 0.1892 - val_loss: 2.6459 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 217/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2852 - loss: 2.282\n",
      "Epoch 217: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2579 - loss: 2.3228 - val_accuracy: 0.1892 - val_loss: 2.6560 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 218/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2465 - loss: 2.369\n",
      "Epoch 218: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2407 - loss: 2.3661 - val_accuracy: 0.1892 - val_loss: 2.6635 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 219/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2201 - loss: 2.446\n",
      "Epoch 219: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2207 - loss: 2.4211 - val_accuracy: 0.1892 - val_loss: 2.6659 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 220/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  - accuracy: 0.2257 - loss: 2.336\n",
      "Epoch 220: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2258 - loss: 2.3396 - val_accuracy: 0.1892 - val_loss: 2.6724 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 221/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  - accuracy: 0.2210 - loss: 2.386\n",
      "Epoch 221: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.2225 - loss: 2.3819 - val_accuracy: 0.1892 - val_loss: 2.6666 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 222/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  - accuracy: 0.2233 - loss: 2.385\n",
      "Epoch 222: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.2237 - loss: 2.3825 - val_accuracy: 0.1892 - val_loss: 2.6637 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 223/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2092 - loss: 2.328\n",
      "Epoch 223: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2140 - loss: 2.3261 - val_accuracy: 0.1892 - val_loss: 2.6721 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 224/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2552 - loss: 2.274\n",
      "Epoch 224: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2444 - loss: 2.3135 - val_accuracy: 0.1892 - val_loss: 2.6809 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 225/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2467 - loss: 2.331\n",
      "Epoch 225: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2408 - loss: 2.3396 - val_accuracy: 0.1892 - val_loss: 2.6684 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 226/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2985 - loss: 2.258\n",
      "Epoch 226: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2779 - loss: 2.2860 - val_accuracy: 0.1892 - val_loss: 2.6621 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 227/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.1954 - loss: 2.423\n",
      "Epoch 227: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.2042 - loss: 2.4083 - val_accuracy: 0.1892 - val_loss: 2.6418 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 228/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2617 - loss: 2.288\n",
      "Epoch 228: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2481 - loss: 2.3228 - val_accuracy: 0.1892 - val_loss: 2.6321 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 229/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2271 - loss: 2.374\n",
      "Epoch 229: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2270 - loss: 2.3705 - val_accuracy: 0.1892 - val_loss: 2.6310 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 230/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2106 - loss: 2.342\n",
      "Epoch 230: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2151 - loss: 2.3485 - val_accuracy: 0.1892 - val_loss: 2.6341 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 231/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2346 - loss: 2.383\n",
      "Epoch 231: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2322 - loss: 2.3826 - val_accuracy: 0.1892 - val_loss: 2.6446 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 232/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.3027 - loss: 2.208\n",
      "Epoch 232: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2808 - loss: 2.2516 - val_accuracy: 0.1892 - val_loss: 2.6435 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 233/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.1617 - loss: 2.400\n",
      "Epoch 233: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1801 - loss: 2.3908 - val_accuracy: 0.1892 - val_loss: 2.6324 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 234/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2444 - loss: 2.353\n",
      "Epoch 234: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2392 - loss: 2.3590 - val_accuracy: 0.1892 - val_loss: 2.6309 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 235/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2617 - loss: 2.277\n",
      "Epoch 235: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2463 - loss: 2.3189 - val_accuracy: 0.1892 - val_loss: 2.6289 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 236/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2188 - loss: 2.505\n",
      "Epoch 236: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2218 - loss: 2.4569 - val_accuracy: 0.1892 - val_loss: 2.6347 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 237/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2450 - loss: 2.340\n",
      "Epoch 237: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.2396 - loss: 2.3452 - val_accuracy: 0.1892 - val_loss: 2.6515 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 238/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  - accuracy: 0.1549 - loss: 2.401\n",
      "Epoch 238: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.1835 - loss: 2.3896 - val_accuracy: 0.1892 - val_loss: 2.6628 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 239/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2662 - loss: 2.273\n",
      "Epoch 239: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.2605 - loss: 2.2851 - val_accuracy: 0.1892 - val_loss: 2.6670 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 240/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.3008 - loss: 2.315\n",
      "Epoch 240: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2704 - loss: 2.3361 - val_accuracy: 0.1892 - val_loss: 2.6681 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 241/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.1927 - loss: 2.364\n",
      "Epoch 241: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2069 - loss: 2.3598 - val_accuracy: 0.1892 - val_loss: 2.6632 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 242/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2773 - loss: 2.282\n",
      "Epoch 242: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2553 - loss: 2.3063 - val_accuracy: 0.1892 - val_loss: 2.6595 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 243/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2578 - loss: 2.402\n",
      "Epoch 243: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2441 - loss: 2.3859 - val_accuracy: 0.1892 - val_loss: 2.6606 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 244/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2871 - loss: 2.377\n",
      "Epoch 244: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2697 - loss: 2.3741 - val_accuracy: 0.1892 - val_loss: 2.6672 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 245/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.1825 - loss: 2.388\n",
      "Epoch 245: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1950 - loss: 2.3816 - val_accuracy: 0.1892 - val_loss: 2.6715 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 246/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2141 - loss: 2.356\n",
      "Epoch 246: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.2158 - loss: 2.3621 - val_accuracy: 0.1892 - val_loss: 2.6739 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 247/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.1846 - loss: 2.404\n",
      "Epoch 247: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1965 - loss: 2.3954 - val_accuracy: 0.1892 - val_loss: 2.6582 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 248/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.1608 - loss: 2.430\n",
      "Epoch 248: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.1701 - loss: 2.4221 - val_accuracy: 0.1892 - val_loss: 2.6563 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 249/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2279 - loss: 2.396\n",
      "Epoch 249: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2288 - loss: 2.3725 - val_accuracy: 0.1892 - val_loss: 2.6620 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 250/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.3086 - loss: 2.247\n",
      "Epoch 250: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2731 - loss: 2.3068 - val_accuracy: 0.1892 - val_loss: 2.6646 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 251/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2045 - loss: 2.423\n",
      "Epoch 251: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.2076 - loss: 2.4126 - val_accuracy: 0.1892 - val_loss: 2.6598 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 252/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2539 - loss: 2.364\n",
      "Epoch 252: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2436 - loss: 2.3552 - val_accuracy: 0.1892 - val_loss: 2.6586 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 253/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2115 - loss: 2.371\n",
      "Epoch 253: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2136 - loss: 2.3693 - val_accuracy: 0.1892 - val_loss: 2.6500 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 254/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.1693 - loss: 2.379\n",
      "Epoch 254: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1953 - loss: 2.3722 - val_accuracy: 0.1892 - val_loss: 2.6463 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 255/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  - accuracy: 0.2292 - loss: 2.339\n",
      "Epoch 255: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2259 - loss: 2.3508 - val_accuracy: 0.1892 - val_loss: 2.6484 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 256/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2409 - loss: 2.348\n",
      "Epoch 256: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2344 - loss: 2.3447 - val_accuracy: 0.1892 - val_loss: 2.6546 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 257/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2031 - loss: 2.391\n",
      "Epoch 257: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2111 - loss: 2.3840 - val_accuracy: 0.1892 - val_loss: 2.6544 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 258/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.1669 - loss: 2.473\n",
      "Epoch 258: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.1838 - loss: 2.4375 - val_accuracy: 0.1892 - val_loss: 2.6501 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 259/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2096 - loss: 2.389\n",
      "Epoch 259: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.2166 - loss: 2.3783 - val_accuracy: 0.1892 - val_loss: 2.6497 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 260/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/stepp - accuracy: 0.2221 - loss: 2.30\n",
      "Epoch 260: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2233 - loss: 2.3259 - val_accuracy: 0.1892 - val_loss: 2.6490 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 261/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.1935 - loss: 2.393\n",
      "Epoch 261: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2029 - loss: 2.3849 - val_accuracy: 0.1892 - val_loss: 2.6460 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 262/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2700 - loss: 2.304\n",
      "Epoch 262: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2575 - loss: 2.3197 - val_accuracy: 0.1892 - val_loss: 2.6546 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 263/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.1665 - loss: 2.380\n",
      "Epoch 263: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.1835 - loss: 2.3742 - val_accuracy: 0.1892 - val_loss: 2.6574 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 264/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2023 - loss: 2.391\n",
      "Epoch 264: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.2091 - loss: 2.3890 - val_accuracy: 0.1892 - val_loss: 2.6567 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 265/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2163 - loss: 2.288\n",
      "Epoch 265: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2191 - loss: 2.3070 - val_accuracy: 0.1892 - val_loss: 2.6640 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 266/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.1992 - loss: 2.370\n",
      "Epoch 266: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.2069 - loss: 2.3673 - val_accuracy: 0.1892 - val_loss: 2.6563 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 267/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2044 - loss: 2.307\n",
      "Epoch 267: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2106 - loss: 2.3176 - val_accuracy: 0.1892 - val_loss: 2.6593 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 268/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2228 - loss: 2.403\n",
      "Epoch 268: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.2233 - loss: 2.3997 - val_accuracy: 0.1892 - val_loss: 2.6594 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 269/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2513 - loss: 2.374\n",
      "Epoch 269: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.2404 - loss: 2.3622 - val_accuracy: 0.1892 - val_loss: 2.6594 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 270/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2165 - loss: 2.326\n",
      "Epoch 270: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2192 - loss: 2.3293 - val_accuracy: 0.1892 - val_loss: 2.6635 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 271/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2578 - loss: 2.303\n",
      "Epoch 271: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2423 - loss: 2.3319 - val_accuracy: 0.1892 - val_loss: 2.6654 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 272/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2318 - loss: 2.274\n",
      "Epoch 272: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2292 - loss: 2.3011 - val_accuracy: 0.1892 - val_loss: 2.6778 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 273/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2106 - loss: 2.375\n",
      "Epoch 273: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2151 - loss: 2.3721 - val_accuracy: 0.1892 - val_loss: 2.6822 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 274/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2005 - loss: 2.437\n",
      "Epoch 274: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2131 - loss: 2.4069 - val_accuracy: 0.1892 - val_loss: 2.6670 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 275/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2092 - loss: 2.427\n",
      "Epoch 275: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2140 - loss: 2.4120 - val_accuracy: 0.1892 - val_loss: 2.6467 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 276/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2115 - loss: 2.319\n",
      "Epoch 276: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2136 - loss: 2.3229 - val_accuracy: 0.1892 - val_loss: 2.6502 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 277/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.1929 - loss: 2.423\n",
      "Epoch 277: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2024 - loss: 2.4085 - val_accuracy: 0.1892 - val_loss: 2.6513 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 278/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2228 - loss: 2.315\n",
      "Epoch 278: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2233 - loss: 2.3243 - val_accuracy: 0.1892 - val_loss: 2.6616 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 279/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2596 - loss: 2.271\n",
      "Epoch 279: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2500 - loss: 2.2966 - val_accuracy: 0.1892 - val_loss: 2.6725 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 280/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2393 - loss: 2.328\n",
      "Epoch 280: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2374 - loss: 2.3311 - val_accuracy: 0.1892 - val_loss: 2.6808 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 281/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2360 - loss: 2.354\n",
      "Epoch 281: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2332 - loss: 2.3544 - val_accuracy: 0.1892 - val_loss: 2.6808 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 282/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2799 - loss: 2.264\n",
      "Epoch 282: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2567 - loss: 2.3032 - val_accuracy: 0.1892 - val_loss: 2.6719 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 283/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2396 - loss: 2.324\n",
      "Epoch 283: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.2355 - loss: 2.3386 - val_accuracy: 0.1892 - val_loss: 2.6673 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 284/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2956 - loss: 2.251\n",
      "Epoch 284: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2675 - loss: 2.2876 - val_accuracy: 0.1892 - val_loss: 2.6647 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 285/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2917 - loss: 2.292\n",
      "Epoch 285: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.2634 - loss: 2.3259 - val_accuracy: 0.1892 - val_loss: 2.6538 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 286/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2200 - loss: 2.418\n",
      "Epoch 286: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2218 - loss: 2.4096 - val_accuracy: 0.1892 - val_loss: 2.6474 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 287/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step  - accuracy: 0.2371 - loss: 2.376\n",
      "Epoch 287: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.2340 - loss: 2.3711 - val_accuracy: 0.1892 - val_loss: 2.6480 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 288/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.1737 - loss: 2.437\n",
      "Epoch 288: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1887 - loss: 2.4138 - val_accuracy: 0.1892 - val_loss: 2.6545 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 289/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  - accuracy: 0.3225 - loss: 2.311\n",
      "Epoch 289: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2950 - loss: 2.3238 - val_accuracy: 0.1892 - val_loss: 2.6669 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 290/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step  - accuracy: 0.2362 - loss: 2.324\n",
      "Epoch 290: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2334 - loss: 2.3326 - val_accuracy: 0.1892 - val_loss: 2.6709 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 291/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step  - accuracy: 0.2371 - loss: 2.299\n",
      "Epoch 291: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2340 - loss: 2.3215 - val_accuracy: 0.1892 - val_loss: 2.6815 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 292/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2081 - loss: 2.370\n",
      "Epoch 292: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.2133 - loss: 2.3672 - val_accuracy: 0.1892 - val_loss: 2.6764 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 293/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step  - accuracy: 0.2600 - loss: 2.350\n",
      "Epoch 293: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2503 - loss: 2.3469 - val_accuracy: 0.1892 - val_loss: 2.6801 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 294/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2215 - loss: 2.366\n",
      "Epoch 294: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.2228 - loss: 2.3614 - val_accuracy: 0.1892 - val_loss: 2.6844 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 295/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2341 - loss: 2.322\n",
      "Epoch 295: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.2329 - loss: 2.3257 - val_accuracy: 0.1892 - val_loss: 2.6884 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 296/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2423 - loss: 2.339\n",
      "Epoch 296: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2377 - loss: 2.3490 - val_accuracy: 0.1892 - val_loss: 2.6781 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 297/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2656 - loss: 2.386\n",
      "Epoch 297: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2503 - loss: 2.3645 - val_accuracy: 0.1892 - val_loss: 2.6618 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 298/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.1935 - loss: 2.418\n",
      "Epoch 298: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2029 - loss: 2.4020 - val_accuracy: 0.1892 - val_loss: 2.6506 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 299/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step  - accuracy: 0.2631 - loss: 2.316\n",
      "Epoch 299: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.2526 - loss: 2.3244 - val_accuracy: 0.1892 - val_loss: 2.6547 - f1_score: 0.0264 - recall: 0.0714\n",
      "Epoch 300/300\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step  - accuracy: 0.2215 - loss: 2.389\n",
      "Epoch 300: f1-score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.2228 - loss: 2.3794 - val_accuracy: 0.1892 - val_loss: 2.6547 - f1_score: 0.0264 - recall: 0.0714\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.2343 - loss: 2.9629 \n",
      "Test Loss: 2.8453409671783447, Test Accuracy: 0.22641509771347046\n"
     ]
    }
   ],
   "source": [
    "classifier = IntentClassifier()\n",
    "X_train, X_test, y_train, y_test = classifier.prepare_data(chats_clients)\n",
    "classifier.build_model(input_shape=(X_train.shape[1], X_train.shape[2]))\n",
    "H = classifier.train(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier.evaluate_model(H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n",
      "53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         6\n",
      "           5       0.00      0.00      0.00         4\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         6\n",
      "           8       0.00      0.00      0.00         3\n",
      "           9       0.23      1.00      0.37        12\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         7\n",
      "          12       0.00      0.00      0.00         2\n",
      "          13       0.00      0.00      0.00         3\n",
      "          14       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.23        53\n",
      "   macro avg       0.02      0.07      0.03        53\n",
      "weighted avg       0.05      0.23      0.08        53\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joaopedroalcaraz/Documents/GitHub/2024-2A-T01-CC11-G03/notebooks/sprint 3/LLM/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/joaopedroalcaraz/Documents/GitHub/2024-2A-T01-CC11-G03/notebooks/sprint 3/LLM/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/joaopedroalcaraz/Documents/GitHub/2024-2A-T01-CC11-G03/notebooks/sprint 3/LLM/venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = classifier.predict(X_test)\n",
    "classifier.generate_report(y_test, y_pred_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calcula a matriz de confusão\n",
    "labels = np.unique(y_test)\n",
    "cm = confusion_matrix(y_test, y_pred_classes, labels=labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

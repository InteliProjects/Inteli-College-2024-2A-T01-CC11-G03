{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pr√©-processamento"
      ],
      "metadata": {
        "id": "4zKtGlTO_k37"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0) Base de Dados (Substituir com os dados da Sarah)"
      ],
      "metadata": {
        "id": "TgQ368mGxOdd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiTEFGx07pDv"
      },
      "outputs": [],
      "source": [
        "# 10 Frases da base de dados do parceiro, usadas inicialmente para testes, antes de integrar com o resto do trabalho do grupo!\n",
        "# Substituir com os dados da Sarah!\n",
        "textos = [\n",
        "    \"\"\"\n",
        "    Como fa√ßo para fazer dep√≥sito\n",
        "    J√° fiz o cadastro na Brastel remit\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    bom dia preciso enviar novamente 970,00 reais, qual valor em ienes por favor???\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    Boa tarde\n",
        "    Gostaria de saber a cota√ß√£o pra 30,000¬• com a taxa, por favor üôè\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    Quero fazer remessa para o Brasil\n",
        "    Como fa√ßo?\n",
        "    Desse novo aplicativo ainda n√£o usei\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    250 reais\n",
        "    Quanto tenho depositar no correio\n",
        "    Por favor\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    Oi\n",
        "    Boa tarde\n",
        "    Para chegar no brasil 982 reais quanto tenho que mandar?\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    Como posso me inscrever no servi√ßo de remessa?\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    Boa noite preciso mandar 520 reais para o Brasil quanto seria em yen\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    Quanto tempo levar√° para o benefici√°rio receber o dinheiro?\n",
        "    \"\"\",\n",
        "    \"\"\"\n",
        "    Qual procedimento para abrir,cadastrar conta?\n",
        "    \"\"\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Reconhecimento de Nomes de Entidades (substituir por quem implementou, de fato) - Carneiro"
      ],
      "metadata": {
        "id": "lkatDnHY_ojG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se quiser, escreve uma pequena descri√ß√£o do que essa parte faz, embasando com uma refer√™ncia da NET. ([Fonte]())"
      ],
      "metadata": {
        "id": "U7RDt9LCMz_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Colocar c√≥digo do Carneiro"
      ],
      "metadata": {
        "id": "d3E1SpnV8WF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1) Resultados Esperados (substituir se acha que faz sentido)\n"
      ],
      "metadata": {
        "id": "qVQlKSaoMQji"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "['Como', 'fa√ßo', 'para', 'fazer', 'dep√≥sito', 'J√°', 'fiz', 'o', 'cadastro', 'na', 'Brastel', 'remit']\n",
        "['bom', 'dia', 'preciso', 'enviar', 'novamente', '970,00', 'reais', ',', 'qual', 'valor', 'em', 'ienes', 'por', 'favor', '?', '?', '?']\n",
        "['Boa', 'tarde', 'Gostaria', 'de', 'saber', 'a', 'cota√ß√£o', 'pra', '30,000', '¬•', 'com', 'a', 'taxa', ',', 'por', 'favor', 'üôè']\n",
        "['Quero', 'fazer', 'remessa', 'para', 'o', 'Brasil', 'Como', 'fa√ßo', '?', 'Desse', 'novo', 'aplicativo', 'ainda', 'n√£o', 'usei']\n",
        "['250', 'reais', 'Quanto', 'tenho', 'depositar', 'no', 'correio', 'Por', 'favor']\n",
        "['Oi', 'Boa', 'tarde', 'Para', 'chegar', 'no', 'brasil', '982', 'reais', 'quanto', 'tenho', 'que', 'mandar', '?']\n",
        "['Como', 'posso', 'me', 'inscrever', 'no', 'servi√ßo', 'de', 'remessa', '?']\n",
        "['Boa', 'noite', 'preciso', 'mandar', '520', 'reais', 'para', 'o', 'Brasil', 'quanto', 'seria', 'em', 'yen']\n",
        "['Quanto', 'tempo', 'levar√°', 'para', 'o', 'benefici√°rio', 'receber', 'o', 'dinheiro', '?']\n",
        "['Qual', 'procedimento', 'para', 'abrir', ',', 'cadastrar', 'conta', '?']\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "dMm0ya1iQXMH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2) Resultados Obtidos"
      ],
      "metadata": {
        "id": "pcuspynTMTlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Colocar chamada para a fun√ß√£o, se quiser seguindo o seguinte padr√£o:\n",
        "\n",
        "print(f\"Frase {p+1}: {tokens}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHswn0zOMoEs",
        "outputId": "0211cb63-b1f2-429c-8ae9-1ebc59f060e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frase 1: ['Como', 'fa√ßo', 'para', 'fazer', 'dep√≥sito', 'J√°', 'fiz', 'o', 'cadastro', 'na', 'Brastel', 'remit']\n",
            "Frase 2: ['bom', 'dia', 'preciso', 'enviar', 'novamente', '970,00', 'reais', ',', 'qual', 'valor', 'em', 'ienes', 'por', 'favor', '?', '?', '?']\n",
            "Frase 3: ['Boa', 'tarde', 'Gostaria', 'de', 'saber', 'a', 'cota√ß√£o', 'pra', '30,000', '¬•', 'com', 'a', 'taxa', ',', 'por', 'favor', 'üôè']\n",
            "Frase 4: ['Quero', 'fazer', 'remessa', 'para', 'o', 'Brasil', 'Como', 'fa√ßo', '?', 'Desse', 'novo', 'aplicativo', 'ainda', 'n√£o', 'usei']\n",
            "Frase 5: ['250', 'reais', 'Quanto', 'tenho', 'depositar', 'no', 'correio', 'Por', 'favor']\n",
            "Frase 6: ['Oi', 'Boa', 'tarde', 'Para', 'chegar', 'no', 'brasil', '982', 'reais', 'quanto', 'tenho', 'que', 'mandar', '?']\n",
            "Frase 7: ['Como', 'posso', 'me', 'inscrever', 'no', 'servi√ßo', 'de', 'remessa', '?']\n",
            "Frase 8: ['Boa', 'noite', 'preciso', 'mandar', '520', 'reais', 'para', 'o', 'Brasil', 'quanto', 'seria', 'em', 'yen']\n",
            "Frase 9: ['Quanto', 'tempo', 'levar√°', 'para', 'o', 'benefici√°rio', 'receber', 'o', 'dinheiro', '?']\n",
            "Frase 10: ['Qual', 'procedimento', 'para', 'abrir', ',', 'cadastrar', 'conta', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Tokeniza√ß√£o (substituir por quem implementou, de fato) - Sarah"
      ],
      "metadata": {
        "id": "RCV_tImtzV81"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Tokeniza√ß√£o consiste no processo de divis√£o de um texto em partes menores, tokens, sejam elas palavras, caracteres ou at√© frases, de forma que o modelo de LLM possa processar e manipular os tokens com os algoritmos. Esse processo √© a primeira etapa do treinamento do modelo e essencial para o resultado das outras etapas. ([Fonte](https://learn.microsoft.com/pt-br/dotnet/ai/conceptual/understanding-tokens))"
      ],
      "metadata": {
        "id": "_YOc1N8EzV9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def tokenizar(texto):\n",
        "    texto = re.sub(r'\\s+', ' ', texto) #substitui mais de um espa√ßo por um √∫nico\n",
        "    tokens = re.findall(r'\\d+,\\d+|\\d+\\.\\d+|\\w+|[^\\w\\s]', texto) #separa as palavras das pontua√ß√µes e mant√©m n√∫meros decimais ou com ponto juntos (estava errado sem os \"d\" - n¬∫)\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "669Pla8VzV9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1) Resultados Esperados (substituir se acha que faz sentido)\n"
      ],
      "metadata": {
        "id": "9wS5fG2lzV9E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "['Como', 'fa√ßo', 'para', 'fazer', 'dep√≥sito', 'J√°', 'fiz', 'o', 'cadastro', 'na', 'Brastel', 'remit']\n",
        "['bom', 'dia', 'preciso', 'enviar', 'novamente', '970,00', 'reais', ',', 'qual', 'valor', 'em', 'ienes', 'por', 'favor', '?', '?', '?']\n",
        "['Boa', 'tarde', 'Gostaria', 'de', 'saber', 'a', 'cota√ß√£o', 'pra', '30,000', '¬•', 'com', 'a', 'taxa', ',', 'por', 'favor', 'üôè']\n",
        "['Quero', 'fazer', 'remessa', 'para', 'o', 'Brasil', 'Como', 'fa√ßo', '?', 'Desse', 'novo', 'aplicativo', 'ainda', 'n√£o', 'usei']\n",
        "['250', 'reais', 'Quanto', 'tenho', 'depositar', 'no', 'correio', 'Por', 'favor']\n",
        "['Oi', 'Boa', 'tarde', 'Para', 'chegar', 'no', 'brasil', '982', 'reais', 'quanto', 'tenho', 'que', 'mandar', '?']\n",
        "['Como', 'posso', 'me', 'inscrever', 'no', 'servi√ßo', 'de', 'remessa', '?']\n",
        "['Boa', 'noite', 'preciso', 'mandar', '520', 'reais', 'para', 'o', 'Brasil', 'quanto', 'seria', 'em', 'yen']\n",
        "['Quanto', 'tempo', 'levar√°', 'para', 'o', 'benefici√°rio', 'receber', 'o', 'dinheiro', '?']\n",
        "['Qual', 'procedimento', 'para', 'abrir', ',', 'cadastrar', 'conta', '?']\n",
        "\n",
        "```"
      ],
      "metadata": {
        "id": "EvKcvpPGzV9E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2) Resultados Obtidos"
      ],
      "metadata": {
        "id": "Rmhnm6iAzV9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Segmentar tokens\n",
        "teste_tokenizacao = [tokenizar(texto) for texto in textos]\n",
        "\n",
        "# Exibir resultados da tokeniza√ß√£o\n",
        "for i, tokens in enumerate(teste_tokenizacao):\n",
        "    print(f\"Frase {i+1}: {tokens}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0211cb63-b1f2-429c-8ae9-1ebc59f060e9",
        "id": "FC64ybB_zV9F"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frase 1: ['Como', 'fa√ßo', 'para', 'fazer', 'dep√≥sito', 'J√°', 'fiz', 'o', 'cadastro', 'na', 'Brastel', 'remit']\n",
            "Frase 2: ['bom', 'dia', 'preciso', 'enviar', 'novamente', '970,00', 'reais', ',', 'qual', 'valor', 'em', 'ienes', 'por', 'favor', '?', '?', '?']\n",
            "Frase 3: ['Boa', 'tarde', 'Gostaria', 'de', 'saber', 'a', 'cota√ß√£o', 'pra', '30,000', '¬•', 'com', 'a', 'taxa', ',', 'por', 'favor', 'üôè']\n",
            "Frase 4: ['Quero', 'fazer', 'remessa', 'para', 'o', 'Brasil', 'Como', 'fa√ßo', '?', 'Desse', 'novo', 'aplicativo', 'ainda', 'n√£o', 'usei']\n",
            "Frase 5: ['250', 'reais', 'Quanto', 'tenho', 'depositar', 'no', 'correio', 'Por', 'favor']\n",
            "Frase 6: ['Oi', 'Boa', 'tarde', 'Para', 'chegar', 'no', 'brasil', '982', 'reais', 'quanto', 'tenho', 'que', 'mandar', '?']\n",
            "Frase 7: ['Como', 'posso', 'me', 'inscrever', 'no', 'servi√ßo', 'de', 'remessa', '?']\n",
            "Frase 8: ['Boa', 'noite', 'preciso', 'mandar', '520', 'reais', 'para', 'o', 'Brasil', 'quanto', 'seria', 'em', 'yen']\n",
            "Frase 9: ['Quanto', 'tempo', 'levar√°', 'para', 'o', 'benefici√°rio', 'receber', 'o', 'dinheiro', '?']\n",
            "Frase 10: ['Qual', 'procedimento', 'para', 'abrir', ',', 'cadastrar', 'conta', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) Remo√ß√£o de Stop Words (substituir por quem implementou, de fato)\n"
      ],
      "metadata": {
        "id": "SEfUzfQR_slx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A etapa de remo√ß√£o de Stop Words √© um processo de refinamento e elimina√ß√£o de palavras irrelevantes para o processamento do modelo de LLM, ao consultar em uma lista de palavras irrelevantes no idioma em quest√£o. Assim, a dimensionalidade do problema √© diminu√≠da e a efici√™ncia do modelo aumentada com a elimina√ß√£o de palavras irrelevantes, como \"a\", \"e\", \"de\". ([Fonte](https://fineproxy.org/pt/wiki/stopword-removal/#:~:text=A%20remo%C3%A7%C3%A3o%20de%20palavras%20de,automatizado%20e%20classifica%C3%A7%C3%A3o%20de%20textos.))"
      ],
      "metadata": {
        "id": "y3lATBMLM4Hx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "# Baixa a lista de stop words\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "def remover_stop_words(texto):\n",
        "    # Lista de stop words em portugu√™s\n",
        "    stop_words = set(stopwords.words('portuguese'))\n",
        "    # Tokeniza o texto\n",
        "    tokens = tokenizar(texto)\n",
        "    # Filtra as stop words\n",
        "    tokens_filtrados = [token for token in tokens if token.lower() not in stop_words]\n",
        "\n",
        "    return tokens_filtrados"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBRP0kEm6lef",
        "outputId": "1f887e75-aa27-47b9-8af5-9afa8d3ad39a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1) Resultados Esperados"
      ],
      "metadata": {
        "id": "pV4bBdA2MbvZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "['fa√ßo', 'fazer', 'dep√≥sito', 'fiz', 'cadastro', 'Brastel', 'remit']\n",
        "['bom', 'dia', 'preciso', 'enviar', 'novamente', '970,00', 'reais', ',', 'valor', 'ienes', 'favor', '?', '?', '?']\n",
        "['Boa', 'tarde', 'Gostaria', 'saber', 'cota√ß√£o', 'pra', '30,000', '¬•', 'taxa', ',', 'favor', 'üôè']\n",
        "['Quero', 'fazer', 'remessa', 'Brasil', 'fa√ßo', '?', 'Desse', 'novo', 'aplicativo', 'ainda', 'usei']\n",
        "['250', 'reais', 'Quanto', 'depositar', 'correio', 'favor']\n",
        "['Oi', 'Boa', 'tarde', 'chegar', 'brasil', '982', 'reais', 'quanto', 'mandar', '?']\n",
        "['posso', 'inscrever', 'servi√ßo', 'remessa', '?']\n",
        "['Boa', 'noite', 'preciso', 'mandar', '520', 'reais', 'Brasil', 'quanto', 'yen']\n",
        "['Quanto', 'tempo', 'levar√°', 'benefici√°rio', 'receber', 'dinheiro', '?']\n",
        "['procedimento', 'abrir', ',', 'cadastrar', 'conta', '?']\n",
        "```"
      ],
      "metadata": {
        "id": "Mev7QFeZ-kwM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2) Resultados Obtidos"
      ],
      "metadata": {
        "id": "wOCC6jRkMf_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exibir resultados da remo√ß√£o de stop words\n",
        "x = -1\n",
        "for texto in textos:\n",
        "    x += 1\n",
        "    tokens_sem_stop_words = remover_stop_words(texto)\n",
        "    print(f\"Frase {x+1}: {tokens_sem_stop_words}\")"
      ],
      "metadata": {
        "id": "RGYKm-1IMfwQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14af73f0-f16c-4852-c729-e11da3c82804"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frase 1: ['fa√ßo', 'fazer', 'dep√≥sito', 'fiz', 'cadastro', 'Brastel', 'remit']\n",
            "Frase 2: ['bom', 'dia', 'preciso', 'enviar', 'novamente', '970,00', 'reais', ',', 'valor', 'ienes', 'favor', '?', '?', '?']\n",
            "Frase 3: ['Boa', 'tarde', 'Gostaria', 'saber', 'cota√ß√£o', 'pra', '30,000', '¬•', 'taxa', ',', 'favor', 'üôè']\n",
            "Frase 4: ['Quero', 'fazer', 'remessa', 'Brasil', 'fa√ßo', '?', 'Desse', 'novo', 'aplicativo', 'ainda', 'usei']\n",
            "Frase 5: ['250', 'reais', 'Quanto', 'depositar', 'correio', 'favor']\n",
            "Frase 6: ['Oi', 'Boa', 'tarde', 'chegar', 'brasil', '982', 'reais', 'quanto', 'mandar', '?']\n",
            "Frase 7: ['posso', 'inscrever', 'servi√ßo', 'remessa', '?']\n",
            "Frase 8: ['Boa', 'noite', 'preciso', 'mandar', '520', 'reais', 'Brasil', 'quanto', 'yen']\n",
            "Frase 9: ['Quanto', 'tempo', 'levar√°', 'benefici√°rio', 'receber', 'dinheiro', '?']\n",
            "Frase 10: ['procedimento', 'abrir', ',', 'cadastrar', 'conta', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) Lematiza√ß√£o"
      ],
      "metadata": {
        "id": "tENoHhQzEHRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A Lematiza√ß√£o √© o processo de extrair o infinitivo dos verbos, de forma que haja uma padroniza√ß√£o na utiliza√ß√£o das palavras. Isso √© importante para a rede reconhecer de forma mais simples os padr√µes entre os tokens. ([Fonte](https://blog.bitso.com/pt-br/criptomoedas/diferenca-entre-tokenizacao-e-lematizacao#:~:text=Lematiza%C3%A7%C3%A3o%20%C3%A9%20um%20tipo%20de,fim%20de%20simplificar%20a%20palavra.))"
      ],
      "metadata": {
        "id": "e1vH5WALM7CT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy\n",
        "!python -m spacy download pt_core_news_sm\n",
        "\n",
        "import spacy\n",
        "\n",
        "nlp = spacy.load('pt_core_news_sm')\n",
        "\n",
        "def lematizar(texto):\n",
        "    texto = ' '.join(texto)  # Fundamental para preservar o formato de entrada\n",
        "    doc = nlp(texto)\n",
        "    token_lematizado = [token.lemma_ for token in doc]  # Aplica a lematiza√ß√£o em cada token\n",
        "\n",
        "    return token_lematizado\n",
        "\n",
        "# Caso os dados da Sarah venham em em colunas de um dataframe:\n",
        "\n",
        "# def lematizar(texto):\n",
        "#     texto = ' '.join(texto)  # Fundamental para preservar o formato de entrada\n",
        "#     doc = nlp(texto)\n",
        "#     token_lematizado = [token.lemma_ for token in doc]  # Aplica a lematiza√ß√£o em cada token\n",
        "\n",
        "#     return token_lematizado\n",
        "\n",
        "# # Aplicando a lematiza√ß√£o √†s colunas 'Pergunta' e 'Resposta'\n",
        "# chats_clients['Pergunta_Lematizada'] = chats_clients['Pergunta'].apply(lematizar)\n",
        "# chats_clients['Resposta_Lematizada'] = chats_clients['Resposta'].apply(lematizar)"
      ],
      "metadata": {
        "id": "VRQTJX2jEI7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "f5b0b093-bd1e-458a-f1ca-1fcd3bf2f079"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting pt-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.7.0/pt_core_news_sm-3.7.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from pt-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (4.66.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (71.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1) Resultados Esperados (substituir pelo conjunto de dados reais)"
      ],
      "metadata": {
        "id": "92q8e-VHMpqk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "['fazer', 'fazer', 'dep√≥sito', 'fazer', 'cadastro', 'Brastel', 'remit']\n",
        "['bom', 'dia', 'precisar', 'enviar', 'novamente', '970,00', 'real', ',', 'valor', 'iene', 'favor', '?', '?', '?']\n",
        "['Boa', 'tarde', 'Gostar', 'saber', 'cota√ß√£o', 'pra', '30,000', '¬•', 'taxa', ',', 'favor', 'üôè']\n",
        "['querer', 'fazer', 'remessa', 'Brasil', 'fazer', '?', 'Desse', 'novo', 'aplicativo', 'ainda', 'usei']\n",
        "['250', 'real', 'quanto', 'depositar', 'correio', 'favor']\n",
        "['Oi', 'Boa', 'tarde', 'chegar', 'Brasil', '982', 'real', 'quanto', 'mandar', '?']\n",
        "['poder', 'inscrever', 'servi√ßo', 'remessa', '?']\n",
        "['Boa', 'noite', 'precisar', 'mandar', '520', 'real', 'Brasil', 'quanto', 'yen']\n",
        "['quanto', 'tempo', 'levar', 'benefici√°rio', 'receber', 'dinheiro', '?']\n",
        "['procedimento', 'abrir', ',', 'cadastrar', 'conta', '?']\n",
        "```"
      ],
      "metadata": {
        "id": "xoPVtKaaHXl8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2) Resultados Obtidos"
      ],
      "metadata": {
        "id": "BexaoNZDMrzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = -1\n",
        "for texto in textos:\n",
        "    y += 1\n",
        "    tokens_sem_stop_words = remover_stop_words(texto)\n",
        "    tokens_lematizados = lematizar(tokens_sem_stop_words)\n",
        "    print(f\"Frase {y+1}: {tokens_lematizados}\")\n",
        "\n",
        "#Caso seja utilizado um DF, printar da seguinte forma:\n",
        "# Exibir o DataFrame com as colunas lematizadas\n",
        "#print(chats_clients[['Pergunta_Lematizada', 'Resposta_Lematizada']])"
      ],
      "metadata": {
        "id": "iKowhIkXMuPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9456831a-d8cc-4ac9-f047-ff324ab50c3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frase 1: ['fazer', 'fazer', 'dep√≥sito', 'fiz', 'cadastro', 'Brastel', 'remitr']\n",
            "Frase 2: ['bom', 'dia', 'preciso', 'enviar', 'novamente', '970,00', 'real', ',', 'valor', 'iene', 'favor', '?', '?', '?']\n",
            "Frase 3: ['Boa', 'tarde', 'Gostaria', 'saber', 'cota√ß√£o', 'pra', '30,000', '¬•', 'taxa', ',', 'favor', 'üôè']\n",
            "Frase 4: ['querer', 'fazer', 'remesso', 'Brasil', 'fazer', '?', 'de esse', 'novo', 'aplicativo', 'ainda', 'usei']\n",
            "Frase 5: ['250', 'real', 'quanto', 'depositar', 'correio', 'favor']\n",
            "Frase 6: ['Oi', 'Boa', 'tarde', 'chegar', 'Brasil', '982', 'real', 'quanto', 'mandar', '?']\n",
            "Frase 7: ['poder', 'inscrever', 'servi√ßo', 'remesso', '?']\n",
            "Frase 8: ['Boa', 'noite', 'preciso', 'mandar', '520', 'real', 'Brasil', 'quanto', 'yen']\n",
            "Frase 9: ['quanto', 'tempo', 'levar', 'benefici√°rio', 'receber', 'dinheiro', '?']\n",
            "Frase 10: ['procedimento', 'abrir', ',', 'cadastrar', 'conta', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esses resultados n√£o est√£o perfeitamente equivalentes com o esperado por poss√≠veis limita√ß√µes da biblioteca utilizada."
      ],
      "metadata": {
        "id": "G9DD1g3zH4z9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Stemming"
      ],
      "metadata": {
        "id": "O8qhW4WwsAi8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O stemming √© o processo de remover sufixos e prefixos, deixando os verbos em sua forma base (raiz), de forma semelhante √† Lematiza√ß√£o. O stemming √© considerado um processo mais agressivo que a Lematiza√ß√£o, ent√£o pode gerar radicais que n√£o s√£o palavras reais. [Fonte](https://www.alura.com.br/artigos/lemmatization-vs-stemming-quando-usar-cada-um)"
      ],
      "metadata": {
        "id": "_tcuIzEtsLUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# df_palavras['nltk_stemmer'] = [stemmer.stem(palavra) for palavra in df_palavras['Original']]\n",
        "# df_palavras\n",
        "\n",
        "nltk.download('rslp')\n",
        "from nltk.stem import RSLPStemmer\n",
        "\n",
        "def aplicar_stemming(tokens):\n",
        "    stemmer = RSLPStemmer()\n",
        "    stems = [stemmer.stem(token) for token in tokens]\n",
        "    return stems\n",
        "\n",
        "# Se precisar aplicar em um DF:\n",
        "# def aplicar_stemming(tokens):\n",
        "#     stemmer = RSLPStemmer()\n",
        "#     stems = [stemmer.stem(token) for token in tokens]\n",
        "#     return stems\n",
        "\n",
        "# # Aplicando o stemming √†s colunas 'Pergunta' e 'Resposta'\n",
        "# chats_clients['Pergunta_Stemmed'] = chats_clients['Pergunta'].apply(aplicar_stemming)\n",
        "# chats_clients['Resposta_Stemmed'] = chats_clients['Resposta'].apply(aplicar_stemming)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asclO2AFsNTT",
        "outputId": "70750f85-15c7-4906-ad0d-b7ac0d7e0b74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Package rslp is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.1) Resultados Esperados"
      ],
      "metadata": {
        "id": "j6x1fVAWsMMR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "['fazer', 'fazer', 'dep√≥sito', 'fazer', 'cadastro', 'Brastel', 'remit']\n",
        "['bom', 'dia', 'precisar', 'enviar', 'novamente', '970,00', 'real', ',', 'valor', 'iene', 'favor', '?', '?', '?']\n",
        "['Boa', 'tarde', 'Gostar', 'saber', 'cota√ß√£o', 'pra', '30,000', '¬•', 'taxa', ',', 'favor', 'üôè']\n",
        "['querer', 'fazer', 'remessa', 'Brasil', 'fazer', '?', 'Desse', 'novo', 'aplicativo', 'ainda', 'usei']\n",
        "['250', 'real', 'quanto', 'depositar', 'correio', 'favor']\n",
        "['Oi', 'Boa', 'tarde', 'chegar', 'Brasil', '982', 'real', 'quanto', 'mandar', '?']\n",
        "['poder', 'inscrever', 'servi√ßo', 'remessa', '?']\n",
        "['Boa', 'noite', 'precisar', 'mandar', '520', 'real', 'Brasil', 'quanto', 'yen']\n",
        "['quanto', 'tempo', 'levar', 'benefici√°rio', 'receber', 'dinheiro', '?']\n",
        "['procedimento', 'abrir', ',', 'cadastrar', 'conta', '?']\n",
        "```"
      ],
      "metadata": {
        "id": "QotO-FQEvhfI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2) Resultados Obtidos"
      ],
      "metadata": {
        "id": "l72s30L_vh5t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = -1\n",
        "for texto in textos:\n",
        "    w += 1\n",
        "    tokens_sem_stop_words = remover_stop_words(texto)\n",
        "    tokens_com_stemming = aplicar_stemming(tokens_sem_stop_words)\n",
        "    print(f\"Frase {w+1}: {tokens_com_stemming}\")\n",
        "\n",
        "# Se precisar printar o df:\n",
        "# Exibir o DataFrame com as colunas ap√≥s o stemming\n",
        "# print(chats_clients[['Pergunta_Stemmed', 'Resposta_Stemmed']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYASGSWIvj_h",
        "outputId": "4077887e-1cf9-4046-ba9d-d21fce7f5419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frase 1: ['fa√ß', 'faz', 'dep√≥sit', 'fiz', 'cadastr', 'brastel', 'remit']\n",
            "Frase 2: ['bom', 'dia', 'precis', 'envi', 'nov', '970,00', 'real', ',', 'val', 'ien', 'favor', '?', '?', '?']\n",
            "Frase 3: ['boa', 'tard', 'gost', 'sab', 'cot', 'pra', '30,000', '¬•', 'tax', ',', 'favor', 'üôè']\n",
            "Frase 4: ['quer', 'faz', 'remess', 'brasil', 'fa√ß', '?', 'dess', 'nov', 'aplic', 'aind', 'use']\n",
            "Frase 5: ['250', 'real', 'quant', 'depos', 'correi', 'favor']\n",
            "Frase 6: ['oi', 'boa', 'tard', 'cheg', 'brasil', '982', 'real', 'quant', 'mand', '?']\n",
            "Frase 7: ['poss', 'inscrev', 'servi√ß', 'remess', '?']\n",
            "Frase 8: ['boa', 'noit', 'precis', 'mand', '520', 'real', 'brasil', 'quant', 'yen']\n",
            "Frase 9: ['quant', 'temp', 'lev', 'benefici', 'receb', 'dinh', '?']\n",
            "Frase 10: ['proced', 'abr', ',', 'cadastr', 'cont', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com isso, v√™-se que os resultados obtidos com o Stemming n√£o s√£o nem pr√≥ximos do satisfat√≥rio, sendo, portanto, a escolha da Lematiza√ß√£o uma melhor abordagem para nosso problema"
      ],
      "metadata": {
        "id": "DOBEwiE0wjqv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6) Pipeline completa"
      ],
      "metadata": {
        "id": "pbDudgBXITkr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A fim de simplificar o pr√©-processamento, junta-se todos os processos empregados na seguite fun√ß√£o at√© ent√£o (em desenvolvimento)"
      ],
      "metadata": {
        "id": "KfLLR7grIXcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_processamento(texto):\n",
        "    #substituir pelas fun√ß√µes que foram implementadas de outros membros do grupo, se achar que faz sentido!\n",
        "    tokens_sem_stop_words_finais = remover_stop_words(texto) #substituir pela fun√ß√£o de quem fez a remo√ß√£o do stop words\n",
        "    tokens_lematizados_finais = lematizar(tokens_sem_stop_words_finais)\n",
        "    return tokens_lematizados_finais\n"
      ],
      "metadata": {
        "id": "ER0CeIwZIWx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.1) Resultados Esperados"
      ],
      "metadata": {
        "id": "5tgZ5lGjKc6S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "['fazer', 'fazer', 'dep√≥sito', 'fazer', 'cadastro', 'Brastel', 'remit']\n",
        "['bom', 'dia', 'precisar', 'enviar', 'novamente', '970,00', 'real', ',', 'valor', 'iene', 'favor', '?', '?', '?']\n",
        "['Boa', 'tarde', 'Gostar', 'saber', 'cota√ß√£o', 'pra', '30,000', '¬•', 'taxa', ',', 'favor', 'üôè']\n",
        "['querer', 'fazer', 'remessa', 'Brasil', 'fazer', '?', 'Desse', 'novo', 'aplicativo', 'ainda', 'usei']\n",
        "['250', 'real', 'quanto', 'depositar', 'correio', 'favor']\n",
        "['Oi', 'Boa', 'tarde', 'chegar', 'Brasil', '982', 'real', 'quanto', 'mandar', '?']\n",
        "['poder', 'inscrever', 'servi√ßo', 'remessa', '?']\n",
        "['Boa', 'noite', 'precisar', 'mandar', '520', 'real', 'Brasil', 'quanto', 'yen']\n",
        "['quanto', 'tempo', 'levar', 'benefici√°rio', 'receber', 'dinheiro', '?']\n",
        "['procedimento', 'abrir', ',', 'cadastrar', 'conta', '?']\n",
        "```"
      ],
      "metadata": {
        "id": "awWPM6ehKgQQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6.2) Resultados Obtidos"
      ],
      "metadata": {
        "id": "nFbL5IZQKhY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Aplicando o processamento completo a cada texto\n",
        "z = -1\n",
        "for texto in textos:\n",
        "    z += 1\n",
        "    textos_finais = pre_processamento(texto)\n",
        "    print(f\"Frase {z+1}: {textos_finais}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9p3NrHNkInaY",
        "outputId": "d146e4d3-3c8b-4e32-ea1d-28629cb50997"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frase 1: ['fazer', 'fazer', 'dep√≥sito', 'fiz', 'cadastro', 'Brastel', 'remitr']\n",
            "Frase 2: ['bom', 'dia', 'preciso', 'enviar', 'novamente', '970,00', 'real', ',', 'valor', 'iene', 'favor', '?', '?', '?']\n",
            "Frase 3: ['Boa', 'tarde', 'Gostaria', 'saber', 'cota√ß√£o', 'pra', '30,000', '¬•', 'taxa', ',', 'favor', 'üôè']\n",
            "Frase 4: ['querer', 'fazer', 'remesso', 'Brasil', 'fazer', '?', 'de esse', 'novo', 'aplicativo', 'ainda', 'usei']\n",
            "Frase 5: ['250', 'real', 'quanto', 'depositar', 'correio', 'favor']\n",
            "Frase 6: ['Oi', 'Boa', 'tarde', 'chegar', 'Brasil', '982', 'real', 'quanto', 'mandar', '?']\n",
            "Frase 7: ['poder', 'inscrever', 'servi√ßo', 'remesso', '?']\n",
            "Frase 8: ['Boa', 'noite', 'preciso', 'mandar', '520', 'real', 'Brasil', 'quanto', 'yen']\n",
            "Frase 9: ['quanto', 'tempo', 'levar', 'benefici√°rio', 'receber', 'dinheiro', '?']\n",
            "Frase 10: ['procedimento', 'abrir', ',', 'cadastrar', 'conta', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esses resultados n√£o est√£o perfeitamente equivalentes com o esperado por poss√≠veis limita√ß√µes da biblioteca utilizada."
      ],
      "metadata": {
        "id": "epUrM4wIKmUV"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FKZq-euMKmos"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}